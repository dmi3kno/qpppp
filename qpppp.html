<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Dmytro Perepolkin">
<meta name="author" content="Erik LindstrÃ¶m">
<meta name="author" content="Ullrika Sahlin">
<meta name="keywords" content="quantile functions, quantile-parameterized distributions, expert knowledge elicitation, statistical distributions">

<title>Quantile-parameterized distributions for expert knowledge elicitation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="qpppp_files/libs/clipboard/clipboard.min.js"></script>
<script src="qpppp_files/libs/quarto-html/quarto.js"></script>
<script src="qpppp_files/libs/quarto-html/popper.min.js"></script>
<script src="qpppp_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="qpppp_files/libs/quarto-html/anchor.min.js"></script>
<link href="qpppp_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="qpppp_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="qpppp_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="qpppp_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="qpppp_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
</head><body>% Remove comment where necessary to change font and spacing
%\SingleSpacedXI % 11pt and 1x line spacing
%\SingleSpacedXII % 12pt and 1x line spacing
%\OneAndAHalfSpacedXI % 11pt and 1.5x line spacing
\OneAndAHalfSpacedXII % 12pt and 1.5x line spacing
%\DoubleSpacedXI % 11pt and 2x line spacing
%\DoubleSpacedXII % 12pt and 2x line spacing

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>





<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#past-research" id="toc-past-research" class="nav-link" data-scroll-target="#past-research">Past research</a></li>
  <li><a href="#paper-structure" id="toc-paper-structure" class="nav-link" data-scroll-target="#paper-structure">Paper structure</a></li>
  </ul></li>
  <li><a href="#quantile-parameterization-of-probability-distributions" id="toc-quantile-parameterization-of-probability-distributions" class="nav-link" data-scroll-target="#quantile-parameterization-of-probability-distributions"><span class="header-section-number">2</span> Quantile parameterization of probability distributions</a></li>
  <li><a href="#univariate-quantile-parameterized-distributions" id="toc-univariate-quantile-parameterized-distributions" class="nav-link" data-scroll-target="#univariate-quantile-parameterized-distributions"><span class="header-section-number">3</span> Univariate quantile-parameterized distributions</a>
  <ul class="collapse">
  <li><a href="#myerson-distribution" id="toc-myerson-distribution" class="nav-link" data-scroll-target="#myerson-distribution"><span class="header-section-number">3.1</span> Myerson distribution</a></li>
  <li><a href="#johnson-quantile-parameterized-distribution" id="toc-johnson-quantile-parameterized-distribution" class="nav-link" data-scroll-target="#johnson-quantile-parameterized-distribution"><span class="header-section-number">3.2</span> Johnson Quantile-Parameterized Distribution</a></li>
  <li><a href="#generalisations-of-qpds" id="toc-generalisations-of-qpds" class="nav-link" data-scroll-target="#generalisations-of-qpds"><span class="header-section-number">3.3</span> Generalisations of QPDs</a>
  <ul class="collapse">
  <li><a href="#generalized-johnson-quantile-parameterized-distribution" id="toc-generalized-johnson-quantile-parameterized-distribution" class="nav-link" data-scroll-target="#generalized-johnson-quantile-parameterized-distribution"><span class="header-section-number">3.3.1</span> Generalized Johnson Quantile-Parameterized Distribution</a></li>
  <li><a href="#sec-genmyerson" id="toc-sec-genmyerson" class="nav-link" data-scroll-target="#sec-genmyerson"><span class="header-section-number">3.3.2</span> Generalized Myerson distributions</a></li>
  </ul></li>
  <li><a href="#simple-q-normal-metalog-distributions" id="toc-simple-q-normal-metalog-distributions" class="nav-link" data-scroll-target="#simple-q-normal-metalog-distributions"><span class="header-section-number">3.4</span> Simple Q-Normal, Metalog distributions</a></li>
  <li><a href="#quantile-mixtures" id="toc-quantile-mixtures" class="nav-link" data-scroll-target="#quantile-mixtures"><span class="header-section-number">3.5</span> Quantile mixtures</a></li>
  <li><a href="#other-distributions" id="toc-other-distributions" class="nav-link" data-scroll-target="#other-distributions"><span class="header-section-number">3.6</span> Other distributions</a>
  <ul class="collapse">
  <li><a href="#triangular-and-two-sided-power-distributions" id="toc-triangular-and-two-sided-power-distributions" class="nav-link" data-scroll-target="#triangular-and-two-sided-power-distributions"><span class="header-section-number">3.6.1</span> Triangular and Two-Sided Power distributions</a></li>
  <li><a href="#sec-gld" id="toc-sec-gld" class="nav-link" data-scroll-target="#sec-gld"><span class="header-section-number">3.6.2</span> Generalized Lambda Distribution</a></li>
  </ul></li>
  <li><a href="#sec-qmexample" id="toc-sec-qmexample" class="nav-link" data-scroll-target="#sec-qmexample"><span class="header-section-number">3.7</span> Example</a></li>
  <li><a href="#sec-compareqf" id="toc-sec-compareqf" class="nav-link" data-scroll-target="#sec-compareqf"><span class="header-section-number">3.8</span> Choosing quantile-parameterized distribution</a></li>
  </ul></li>
  <li><a href="#sec-multivariateqpd" id="toc-sec-multivariateqpd" class="nav-link" data-scroll-target="#sec-multivariateqpd"><span class="header-section-number">4</span> Multivariate quantile-parameterized distributions</a>
  <ul class="collapse">
  <li><a href="#mqpds-based-on-standard-multivariate-distributions" id="toc-mqpds-based-on-standard-multivariate-distributions" class="nav-link" data-scroll-target="#mqpds-based-on-standard-multivariate-distributions"><span class="header-section-number">4.1</span> MQPDs based on standard multivariate distributions</a>
  <ul class="collapse">
  <li><a href="#normal-distribution" id="toc-normal-distribution" class="nav-link" data-scroll-target="#normal-distribution"><span class="header-section-number">4.1.1</span> Normal distribution</a></li>
  <li><a href="#logistic-distribution" id="toc-logistic-distribution" class="nav-link" data-scroll-target="#logistic-distribution"><span class="header-section-number">4.1.2</span> Logistic distribution</a></li>
  </ul></li>
  <li><a href="#copula-based-mqpds" id="toc-copula-based-mqpds" class="nav-link" data-scroll-target="#copula-based-mqpds"><span class="header-section-number">4.2</span> Copula-based MQPDs</a></li>
  <li><a href="#bivariate-quantiles" id="toc-bivariate-quantiles" class="nav-link" data-scroll-target="#bivariate-quantiles"><span class="header-section-number">4.3</span> Bivariate quantiles</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion"><span class="header-section-number">5</span> Discussion</a>
  <ul class="collapse">
  <li><a href="#quantile-function-perspective" id="toc-quantile-function-perspective" class="nav-link" data-scroll-target="#quantile-function-perspective">Quantile function perspective</a></li>
  <li><a href="#feasibility-of-parameters" id="toc-feasibility-of-parameters" class="nav-link" data-scroll-target="#feasibility-of-parameters">Feasibility of parameters</a></li>
  <li><a href="#multivariate-extensions" id="toc-multivariate-extensions" class="nav-link" data-scroll-target="#multivariate-extensions">Multivariate extensions</a></li>
  <li><a href="#further-research" id="toc-further-research" class="nav-link" data-scroll-target="#further-research">Further research</a></li>
  </ul></li>
  <li><a href="#miscellaneous" id="toc-miscellaneous" class="nav-link" data-scroll-target="#miscellaneous">Miscellaneous</a>
  <ul class="collapse">
  <li><a href="#acknowledgments" id="toc-acknowledgments" class="nav-link" data-scroll-target="#acknowledgments">Acknowledgments</a></li>
  <li><a href="#orcid" id="toc-orcid" class="nav-link" data-scroll-target="#orcid">ORCID</a></li>
  </ul></li>
  
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="qpppp.pdf"><i class="bi bi-file-pdf"></i>PDF (informs-deca)</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Quantile-parameterized distributions for expert knowledge elicitation</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliations</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://ddrive.no">Dmytro Perepolkin</a> <a href="mailto:dmytro.perepolkin@cec.lu.se" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0003-2402-304X" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Lund University
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Erik LindstrÃ¶m <a href="mailto:erik.lindstrom@matstat.lu.se" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0002-6468-2624" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Lund University
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Ullrika Sahlin <a href="mailto:ullrika.sahlin@cec.lu.se" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0002-2932-6253" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Lund University
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>This paper provides a comprehensive overview of quantile-parameterized distributions (QPDs) as a tool for capturing expert predictions and parametric judgments. We survey a range of methods for constructing distributions that are parameterized by a set of quantile-probability pairs and describe an approach to generalizing them to enhance their tail flexibility. Furthermore, we delve into the extension of QPDs to the multivariate setting, surveying the approaches to construct bivariate distributions, which can be adopted to obtain distributions with quantile-parameterized margins. Through this review and synthesis of the previously proposed methods, we aim to enhance the understanding and utilization of QPDs in various domains.</p>
  </div>
</div>

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>quantile functions, quantile-parameterized distributions, expert knowledge elicitation, statistical distributions</p>
  </div>
</div>

</header>


<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Judgment plays a crucial role in transforming raw data into meaningful insights. To be useful, judgment must be translated into mathematical models and assumptions. These models are designed to capture the expertâs understanding of the world, including the causal links between relevant entities. The models serve as a representation of this understanding, while also addressing knowledge limitations, treated as uncertainties. Elicitation involves translating qualitative understanding into quantitative models offering valuable insights.</p>
<section id="past-research" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="past-research">Past research</h2>
<p>Most of the expert elicitation protocols described in the literature <span class="citation" data-cites="hanea2021ExpertJudgementRisk gosling2018SHELFSheffieldElicitation ohagan2006UncertainJudgementsEliciting hemming2018PracticalGuideStructured morgan2014UseAbuseExpert welsh2018MoreorlessElicitationMOLE spetzler1975ProbabilityEncodingDecision">(<a href="#ref-hanea2021ExpertJudgementRisk" role="doc-biblioref">Hanea et al., 2021</a>; <a href="#ref-gosling2018SHELFSheffieldElicitation" role="doc-biblioref">Gosling, 2018</a>; <a href="#ref-ohagan2006UncertainJudgementsEliciting" role="doc-biblioref">OâHagan et al., 2006</a>; <a href="#ref-hemming2018PracticalGuideStructured" role="doc-biblioref">Hemming et al., 2018</a>; <a href="#ref-morgan2014UseAbuseExpert" role="doc-biblioref">Morgan, 2014</a>; <a href="#ref-welsh2018MoreorlessElicitationMOLE" role="doc-biblioref">Welsh and Begg, 2018</a>; <a href="#ref-spetzler1975ProbabilityEncodingDecision" role="doc-biblioref">Spetzler and StaÃ«l Von Holstein, 1975</a>)</span> encode expert judgments about the parameter or quantity of interest as an ordered set of quantiles with corresponding probabilities. This typically includes measures such as the median and the upper and lower quartiles. Assessors are then encouraged to select a probability distribution that reasonably fits the elicited quantile-probability pairs and validate the choice with the expert <span class="citation" data-cites="gosling2018SHELFSheffieldElicitation">(<a href="#ref-gosling2018SHELFSheffieldElicitation" role="doc-biblioref">Gosling, 2018</a>)</span>. A distribution is selected from a predefined set of âsimple and convenientâ distributions <span class="citation" data-cites="ohagan2006UncertainJudgementsEliciting">(<a href="#ref-ohagan2006UncertainJudgementsEliciting" role="doc-biblioref">OâHagan et al., 2006</a>)</span> with boundedness that accounts for the nature of the elicited quantity.</p>
<p>Several specialized distributions have been developed to facilitate smooth interpolation of probabilistic assessments. These distributions, parameterized by quantile-probability pairs, ensure that the elicited quantile-probability pairs (QPPs) are exactly preserved <span class="citation" data-cites="keelin2011QuantileParameterizedDistributions powley2013QuantileFunctionMethods keelin2016MetalogDistributions hadlock2017QuantileparameterizedMethodsQuantifying wilson2023ReconciliationExpertPriors">(<a href="#ref-keelin2011QuantileParameterizedDistributions" role="doc-biblioref">Keelin and Powley, 2011</a>; <a href="#ref-powley2013QuantileFunctionMethods" role="doc-biblioref">Powley, 2013</a>; <a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>; <a href="#ref-hadlock2017QuantileparameterizedMethodsQuantifying" role="doc-biblioref">Hadlock, 2017</a>; <a href="#ref-wilson2023ReconciliationExpertPriors" role="doc-biblioref">Wilson et al., 2023</a>)</span>. Quantile-parameterized distributions are particularly valuable thanks to the interpretability of their parameters. By leveraging the elicited quantiles, these distributions enable precise capturing of expert knowlegde while maintaining a high level of flexibility in modeling.</p>
<p>We believe that the primary utility of QPDs lies in their ability to simplify the specification of probability distributions for model parameters, known as <em>prior elicitation</em> <span class="citation" data-cites="mikkola2021PriorKnowledgeElicitation">(<a href="#ref-mikkola2021PriorKnowledgeElicitation" role="doc-biblioref">Mikkola et al., 2021</a>)</span>. However, these same distributions can also be employed to describe an expertâs predictions for the next observation, referred to as <em>predictive elicitation</em> <span class="citation" data-cites="winkler1980PriorInformationPredictive kadane1980PredictiveStructuralMethods akbarov2009ProbabilityElicitationPredictive hartmann2020FlexiblePriorElicitation">(<a href="#ref-winkler1980PriorInformationPredictive" role="doc-biblioref">Winkler, 1980</a>; <a href="#ref-kadane1980PredictiveStructuralMethods" role="doc-biblioref">Kadane, 1980</a>; <a href="#ref-akbarov2009ProbabilityElicitationPredictive" role="doc-biblioref">Akbarov, 2009</a>; <a href="#ref-hartmann2020FlexiblePriorElicitation" role="doc-biblioref">Hartmann et al., 2020</a>)</span>, or to capture both uncertainty and variability through a two-dimensional probability distribution in <em>hybrid elicitation</em> <span class="citation" data-cites="perepolkin2021HybridElicitationIndirect">(<a href="#ref-perepolkin2021HybridElicitationIndirect" role="doc-biblioref">Perepolkin et al., 2021</a>)</span>.</p>
<p>This review paper aims to introduce quantile-parameterized distributions (QPDs) to a wide readership. The literature review and the findings are presented through the perspective of quantile functions, building upon the theoretical foundations established by Parzen <span class="citation" data-cites="parzen1979NonparametricStatisticalData">(<a href="#ref-parzen1979NonparametricStatisticalData" role="doc-biblioref">Parzen, 1979</a>)</span> and Gilchrist <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>)</span>. The derivatives and inverses for each of the quantile functions discussed in the paper are provided in Appendix A, serving as a valuable reference for future research. Through our comprehensive review and identification of research gaps, we aim to contribute to the development of flexible and extensible distributions that can effectively capture expert knowledge. We hope that our overview of quantile-parameterized distributions will be useful for researchers and practitioners, enabling them to make an informed choice of a distribution suitable for the task.</p>
</section>
<section id="paper-structure" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="paper-structure">Paper structure</h2>
<p>In Section 2, we revisit the approaches to quantile parameterization of probability distributions and explore how QPDs can effectively describe expert beliefs regarding model parameters or predictions. In Section 3, we conduct a comprehensive review and comparison of various continuous univariate QPDs found in the literature. Specifically, we focus on the Myerson distribution and its generalization accommodating different tail thicknesses. We compare the robust moments of QPDs to assess their flexibility and behavior. This comparative analysis can guide the selection of an appropriate distribution to characterize the quantity of interest. In Section 4, we explore several methods for extending univariate distributions to a multivariate setting. These methods include the utilization of standard multivariate distributions <span class="citation" data-cites="drovandi2011LikelihoodfreeBayesianEstimation">(<a href="#ref-drovandi2011LikelihoodfreeBayesianEstimation" role="doc-biblioref">Drovandi and Pettitt, 2011</a>)</span>, copulas <span class="citation" data-cites="hoff2007ExtendingRankLikelihood">(<a href="#ref-hoff2007ExtendingRankLikelihood" role="doc-biblioref">Hoff, 2007</a>)</span>, and bivariate quantiles <span class="citation" data-cites="nair2023PropertiesBivariateDistributions vineshkumar2019BivariateQuantileFunctions">(<a href="#ref-nair2023PropertiesBivariateDistributions" role="doc-biblioref">Nair and Vineshkumar, 2023</a>; <a href="#ref-vineshkumar2019BivariateQuantileFunctions" role="doc-biblioref">Vineshkumar and Nair, 2019</a>)</span>. We show how these techniques can be applied to develop a bivariate version of the Generalized Myerson distribution and demonstrate its application in parametric and predictive elicitation. Finally, in Section 5, we discuss future research directions and potential applications of QPDs in Bayesian analysis.</p>
</section>
</section>
<section id="quantile-parameterization-of-probability-distributions" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Quantile parameterization of probability distributions</h1>
<p>A fundamental principle in Bayesian data analysis is that learning from data involves more than formulating hypotheses and models. It necessitates articulating prior beliefs, expressing existing knowledge mathematically, and translating it into probability distributions for model parameters.</p>
<p>To accurately translate knowledge into the language of statistical models the encoding distribution needs to be flexible, the process should be transparent, and the results must be interpretable. For continuous distributions, elicitation often consists of capturing a series of quantile-probability pairs (QPPs) <span class="citation" data-cites="kadane1998ExperiencesElicitation morgan2014UseAbuseExpert">(<a href="#ref-kadane1998ExperiencesElicitation" role="doc-biblioref">Kadane and Wolfson, 1998</a>; <a href="#ref-morgan2014UseAbuseExpert" role="doc-biblioref">Morgan, 2014</a>)</span>, and then fitting a distribution to these pairs <span class="citation" data-cites="ohagan2019ExpertKnowledgeElicitation">(<a href="#ref-ohagan2019ExpertKnowledgeElicitation" role="doc-biblioref">OâHagan, 2019</a>)</span>. However, in practice, the choice of a parametric distribution to fit the elicited QPPs is often influenced by concerns about conjugacy with the selected statistical model that represents the data-generative process (the likelihood function) and/or the availability of required distribution functions and fitting algorithms in the software employed. Frequently, the selected distribution possesses fewer parameters than the number of elicited QPPs, which can result in a less-than-perfect fit <span class="citation" data-cites="ohagan2019ExpertKnowledgeElicitation">(<a href="#ref-ohagan2019ExpertKnowledgeElicitation" role="doc-biblioref">OâHagan, 2019</a>)</span>. For instance, it is common to elicit three quantiles (the median along with an upper and lower quartile) and subsequently attempt to fit a normal or lognormal distribution (which features two parameters) to these points.</p>
<p>An alternative approach to characterizing the distribution of predictions or parameters is through quantile-parameterized distributions (QPDs). These distributions are parameterized by the QPPs, allowing the elicited values to directly define the distribution, thereby ensuring a good fit and interpretability of parameters. The QPDs examined in this paper can accommodate a wide range of shapes and boundedness, making them valuable for accurately representing expertsâ prior beliefs.</p>
<p>Parameterizing distributions using a vector of quantiles is not a novel concept in the scientific community. The earliest mention can be traced back to the <em>substitution likelihood</em> proposed by Jeffreys <span class="citation" data-cites="jeffreys1939TheoryProbability">(<a href="#ref-jeffreys1939TheoryProbability" role="doc-biblioref">Jeffreys, 1939</a>)</span>, which outlines a non-parametric procedure for inferring the median using a set of sample quantiles. Subsequently, similar ideas were further developed in <span class="citation" data-cites="boos1986BootstrapMethodsUsing lavine1995ApproximateLikelihoodQuantiles dunson2005ApproximateBayesianInference">(<a href="#ref-boos1986BootstrapMethodsUsing" role="doc-biblioref">Boos and Monahan, 1986</a>; <a href="#ref-lavine1995ApproximateLikelihoodQuantiles" role="doc-biblioref">Lavine, 1995</a>; <a href="#ref-dunson2005ApproximateBayesianInference" role="doc-biblioref">Dunson and Taylor, 2005</a>)</span>.</p>
<p>All the QPDs found in the literature are constructed using the <em>quantile function</em>. These distributions are built either by transforming simpler quantile functions or by simultaneous fitting of parameterizing quantiles, as described below.</p>
<p>Let <span class="math inline">\(Y\)</span> be a random variable with a (cumulative) distribution function (CDF) denoted as <span class="math inline">\(F_Y(y\vert\theta)\)</span>. The quantile function (QF) <span class="math inline">\(Q_Y(u\vert\theta)\)</span> for <span class="math inline">\(Y\)</span> is defined as</p>
<p><span class="math display">\[
Q_Y(u\vert\theta)=\inf\{y:F_Y(y\vert\theta)\geq u\}, \; u\in[0,1]
\]</span></p>
<p>Here, <span class="math inline">\(\theta\)</span> represents the distribution parameter, and the subscript <span class="math inline">\(_Y\)</span> indicates that the depth <span class="math inline">\(u\)</span> corresponds to the random variable <span class="math inline">\(Y\)</span>.</p>
<p>Both the CDF and the QF are considered equally valid ways of defining a distribution <span class="citation" data-cites="tukey1965WhichPartSample">(<a href="#ref-tukey1965WhichPartSample" role="doc-biblioref">Tukey, 1965</a>)</span>. For a quantile function that is right-continuous and strictly increasing over the support of <span class="math inline">\(Y\)</span>, the quantile function <span class="math inline">\(Q_Y(u)\)</span> is simply the inverse of the distribution function, denoted as <span class="math inline">\(Q_Y(u\vert\theta)=F_Y^{-1}(u\vert\theta)\)</span>. Therefore, the quantile function is often referred to as the <em>inverse CDF</em>.</p>
<p>The derivative of the quantile function, known as the <em>quantile density function</em> (QDF), is denoted as <span class="math inline">\(q(u) = \frac{dQ(u)}{du}\)</span>. It is reciprocally related to the probability density function (PDF) <span class="math inline">\(f(x)\)</span>, such that <span class="math inline">\(f(Q(u))q(u) = 1\)</span>. The quantity <span class="math inline">\(f_Y(Q_Y(u\vert\theta))=[q_Y(u\vert\theta)]^{-1}\)</span> is referred to as the <em>density quantile</em> function <span class="citation" data-cites="parzen1979NonparametricStatisticalData">(<a href="#ref-parzen1979NonparametricStatisticalData" role="doc-biblioref">Parzen, 1979</a>)</span> or <em>p-pdf</em> <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>)</span>. The relationships between these functions are concisely illustrated in the probability function MÃ¶bius strip (<a href="#fig-moebius-chart" class="quarto-xref">Figure&nbsp;1</a>).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-moebius-chart" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-moebius-chart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/moebius-loop(1).png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-moebius-chart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: MÃ¶bius strip of probability functions <span class="citation" data-cites="perepolkin2023TenetsQuantilebasedInference">(<a href="#ref-perepolkin2023TenetsQuantilebasedInference" role="doc-biblioref">Perepolkin et al., 2023</a>)</span>
</figcaption>
</figure>
</div>
</div>
</div>
<p>Although many of the distributions discussed in Section 3 have closed-form cumulative distribution functions (CDFs) and probability density functions (PDFs), the functional form of the quantile function (QF) is often simpler and can be reasoned about in terms of other quantile functions, following <em>Gilchristâs QF transformation rules</em> summarized in <a href="#tbl-qf-trans" class="quarto-xref">Table&nbsp;1</a>. This table presents the addition, linear combination, and multiplication rules, which involve two quantile functions <span class="math inline">\(Q_1\)</span> and <span class="math inline">\(Q_2\)</span>. We will refer to these three rules as <em>Gilchrist combinations</em>, as they represent valid ways to combine quantile functions to create new quantile functions.</p>
<div class="cell">
<div id="tbl-qf-trans" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-qf-trans-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Gilchristâs quantile function transformation rules <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>)</span>
</figcaption>
<div aria-describedby="tbl-qf-trans-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">

</div>
</div>
</figure>
</div>
</div>
<p>The quantile-parameterized distributions in this paper are categorized into two groups based on their construction method. The first group comprises distributions that are <em>directly</em> parameterized by the quantile-probability pairs (QPPs). This group includes the Myerson distribution <span class="citation" data-cites="myerson2005ProbabilityModelsEconomic">(<a href="#ref-myerson2005ProbabilityModelsEconomic" role="doc-biblioref">Myerson, 2005</a>)</span>, and the Johnson Quantile-Parameterized Distribution <span class="citation" data-cites="hadlock2017JohnsonQuantileParameterizedDistributions hadlock2019GeneralizedJohnsonQuantileParameterized">(<a href="#ref-hadlock2017JohnsonQuantileParameterizedDistributions" role="doc-biblioref">Hadlock and Bickel, 2017</a>, <a href="#ref-hadlock2019GeneralizedJohnsonQuantileParameterized" role="doc-biblioref">2019</a>)</span>. These distributions are constructed by reparameterizing or transforming existing distributions, following Gilchrist rules (<a href="#tbl-qf-trans" class="quarto-xref">Table&nbsp;1</a>). The transformations used to construct them are detailed in the next section.</p>
<p>The other group of distributions is <em>indirectly</em> parameterized by the QPPs. They require a fitting step where the quantile-probability pairs are translated into distribution parameters, usually through optimization or least-squares methods. This group includes the Simple Q-Normal <span class="citation" data-cites="keelin2011QuantileParameterizedDistributions">(<a href="#ref-keelin2011QuantileParameterizedDistributions" role="doc-biblioref">Keelin and Powley, 2011</a>)</span>, Metalog <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span>, quantile mixtures <span class="citation" data-cites="peng2023MixtureQuantilesEstimated">(<a href="#ref-peng2023MixtureQuantilesEstimated" role="doc-biblioref">Peng et al., 2023</a>)</span>, the variant of the Generalized Lambda Distribution (GLD) by Chalabi et al <span class="citation" data-cites="chalabi2012FlexibleDistributionModeling">(<a href="#ref-chalabi2012FlexibleDistributionModeling" role="doc-biblioref">Chalabi et al., 2012</a>)</span>, and the quantile-parameterized Triangular (Two-Sided Power) distribution by Kotz and van Dorp <span class="citation" data-cites="kotz2004BetaOtherContinuous">(<a href="#ref-kotz2004BetaOtherContinuous" role="doc-biblioref">Kotz and Van Dorp, 2004</a>)</span>. Each distributionâs fitting method is described in the respective subsections below.</p>
</section>
<section id="univariate-quantile-parameterized-distributions" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Univariate quantile-parameterized distributions</h1>
<p>This section reviews various continuous univariate QPDs from the literature. We then discuss the generalized form for these distributions, based on the variations of these QPDs appearing in the literature. For each distribution, we present its quantile function and discuss the parameterization and feasibility conditions. The derivative and inverse of each distribution can be found in Appendix A.</p>
<section id="myerson-distribution" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="myerson-distribution"><span class="header-section-number">3.1</span> Myerson distribution</h2>
<p>One of the earliest examples of a distribution parameterized by quantiles is the <em>generalized log-normal</em> distribution defined by the median and the upper and lower quartiles proposed by <span class="citation" data-cites="myerson2005ProbabilityModelsEconomic">(<a href="#ref-myerson2005ProbabilityModelsEconomic" role="doc-biblioref">Myerson, 2005</a>)</span>. It relies on a transformation of the normal quantile function.</p>
<p>The Myerson distribution can be viewed as parameterized by three quantile values <span class="math inline">\(\{q_1, q_2, q_3\}\)</span>, which correspond to the cumulative probabilities <span class="math inline">\(\{\alpha, 0.5, 1-\alpha\}\)</span>. These quantiles are symmetrical around the median and are defined by the tail parameter <span class="math inline">\(0&lt;\alpha&lt;0.5\)</span>. This type of parameterization is known as the Symmetric Percentile Triplet (SPT, <span class="math inline">\(\alpha\)</span>-level SPT or <span class="math inline">\(\alpha\)</span>-SPT) and is also used in several other quantile-parameterized distributions that we will describe below. The Myerson quantile function is</p>
<p><span class="math display">\[
\begin{gathered}
\rho=q_3-q_2;\;
\beta=\frac{\rho}{q_2-q_1};\;
\kappa(u)=\frac{S(u)}{S(1-\alpha)}\\
Q_Y(u \vert q_1,q_2,q_3,\alpha)=
\begin{cases}
q_2+\rho\frac{\beta^{\kappa(u)}-1}{\beta-1}, \quad &amp;\beta \neq 1\\
q_2+\rho\kappa(u), \quad &amp;\beta =1
\end{cases}
\end{gathered}
\]</span></p>
<p>Here, <span class="math inline">\(u\)</span> represents the depth of the observations of the random variable <span class="math inline">\(Y\)</span> given the parameterizing <span class="math inline">\(\alpha\)</span>-SPT <span class="math inline">\(\{q_1, q_2, q_3, \alpha\}\)</span>, with <span class="math inline">\(0 &lt; \alpha &lt; 0.5\)</span>. The parameter <span class="math inline">\(\rho\)</span> is the <em>upper p-difference</em>, and <span class="math inline">\(\beta\)</span> is the ratio of the inter-percentile ranges, known as the <em>skewness ratio</em> <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000, p. 72</a>)</span>. The <em>kernel</em> quantile function <span class="math inline">\(S(u)\)</span> is equal to the quantile function of the standard normal distribution, also referred to as the probit, defined as <span class="math inline">\(S(u) = \Phi^{-1}(u)\)</span>. The formulas for the derivative and the inverse quantile function of the Myerson QPD can be found in Appendix A.</p>
<p>It is important to note that while the Myerson distribution includes the normal distribution as a special case when the skewness parameter <span class="math inline">\(\beta = 1\)</span>, it can exhibit right-skewness or left-skewness for other values of <span class="math inline">\(\beta\)</span>. In the symmetrical case, the range of the quantile function is <span class="math inline">\((-\infty, \infty)\)</span>. For the right-skewed distribution (<span class="math inline">\(\beta &gt; 1\)</span>), the range is <span class="math inline">\((q_2 - \frac{\rho}{\beta - 1}, \infty)\)</span>, and for the left-skewed distribution (<span class="math inline">\(0 &lt; \beta &lt; 1\)</span>), the range is <span class="math inline">\((-\infty, q_2 - \frac{\rho}{\beta - 1})\)</span>. The limiting case of the skewed Myerson distribution <span class="math inline">\(\lim_{u \rightarrow 0} Q_Y(u\vert\theta)\)</span> for <span class="math inline">\(\beta &gt; 1\)</span> (and the other limit for <span class="math inline">\(0 &lt; \beta &lt; 1\)</span>) possesses some important properties that we discuss in <a href="#sec-genmyerson" class="quarto-xref">Section&nbsp;3.3.2</a> below.</p>
<p>The basic quantile function <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile lampasi2008AlternativeApproachMeasurement">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>; <a href="#ref-lampasi2008AlternativeApproachMeasurement" role="doc-biblioref">Lampasi, 2008</a>)</span> underlying the Myerson distribution is a simple probit, <span class="math inline">\(S(u) = \Phi^{-1}(u)\)</span>, transformed using the exponentiation function <span class="math inline">\(T(x) = \beta^{x}\)</span>, where <span class="math inline">\(\beta &gt; 0\)</span> represents the skewness ratio <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>)</span>. The quantile parameterization is facilitated by <span class="math inline">\(\kappa(u)\)</span>, which takes values <span class="math inline">\(\{-1,0,1\}\)</span> for the three quantiles <span class="math inline">\(\{q_1, q_2, q_3\}\)</span>, such that <span class="math inline">\(Q(\alpha) = q_1\)</span>, <span class="math inline">\(Q(0.5) = q_2\)</span>, and <span class="math inline">\(Q(1 - \alpha) = q_3\)</span>.</p>
</section>
<section id="johnson-quantile-parameterized-distribution" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="johnson-quantile-parameterized-distribution"><span class="header-section-number">3.2</span> Johnson Quantile-Parameterized Distribution</h2>
<p>Hadlock and Bickel <span class="citation" data-cites="hadlock2017QuantileparameterizedMethodsQuantifying">(<a href="#ref-hadlock2017QuantileparameterizedMethodsQuantifying" role="doc-biblioref">Hadlock, 2017</a>)</span> reviewed the existing quantile-parameterized distributions and proposed the quantile parameterization of the Johnson SU family of distributions <span class="citation" data-cites="johnson1994ContinuousUnivariateDistributions">(<a href="#ref-johnson1994ContinuousUnivariateDistributions" role="doc-biblioref">Johnson et al., 1994</a>)</span>. In their paper, Hadlock and Bickel <span class="citation" data-cites="hadlock2017JohnsonQuantileParameterizedDistributions">(<a href="#ref-hadlock2017JohnsonQuantileParameterizedDistributions" role="doc-biblioref">Hadlock and Bickel, 2017</a>)</span> presented two versions of the distribution: the bounded (J-QPD-B) and the semi-bounded (J-QPD-S), both parameterized by an SPT <span class="math inline">\(\{q_1, q_2, q_3, \alpha\}\)</span> and the bound(s).</p>
<p>The J-QPD-B distribution is obtained by applying the inverse-probit transformation to the Johnson SU quantile function <span class="math inline">\(Q_{SU}(u) = \xi + \lambda\sinh(\delta(S(u) + \gamma))\)</span>, where <span class="math inline">\(\delta\)</span> and <span class="math inline">\(\gamma\)</span> are two shape parameters. This function is then rescaled to the compact interval <span class="math inline">\([l_b, u_b]\)</span>. The J-QPD-B quantile function is</p>
<p><span class="math display">\[
\begin{gathered}
Q_B(u\vert q_1, q_2, q_3, \alpha)=
\begin{cases}
l+(u_b-l_b)S^{-1}(\xi+\lambda\sinh(\delta(S(u)+nc))), \quad &amp;n\neq0\\
l+(u_b-l_b)S^{-1}\left(B+\left(\frac{H-L}{2c}\right)S(u)\right), \quad &amp;n=0
\end{cases}
\end{gathered}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\begin{gathered}
S(u)=\Phi^{-1}(u); \quad c=S(1-\alpha);\\
L=S\left(\frac{q_1-l_b}{u_b-l_b}\right); \quad  B=S\left(\frac{q_2-l_b}{u_b-l_b}\right);\\
H=S\left(\frac{q_3-l_b}{u_b-l_b}\right); \quad n=\text{sgn}(L+H-2B)\\
\xi=\begin{cases}L, \quad n=1,\\
B, \quad n=0,\\
H, \quad n=-1,\end{cases}\\
\delta=\frac{1}{c}\cosh^{-1}\left(\frac{H-L}{2\min(B-L,H-B)}\right)\\
\lambda=\frac{H-L}{\sinh(2\delta c)}
\end{gathered}
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-jqpd1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-jqpd1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="qpppp_files/figure-html/fig-jqpd1-1.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-jqpd1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Fitted J-QPD-B (left) and J-QPD-S (right) distribution for prevalence at origin and total trade flow, respectively
</figcaption>
</figure>
</div>
</div>
</div>
<p>The left panel in <a href="#fig-jqpd1" class="quarto-xref">Figure&nbsp;2</a> showcases the J-QPD-B quantile function, which is parameterized using 0.25-SPT and 0.01-SPT assessments of the proportion of fruit infested with <em>Citripestis sagittiferella</em>, as elicited by <span class="citation" data-cites="efsa2023RiskAssessmentCitripestis">(<a href="#ref-efsa2023RiskAssessmentCitripestis" role="doc-biblioref">EFSA et al., 2023</a>)</span>. The dashed line represents the Beta distribution fitted by the authors. The J-QPD-B, being parameterized by an SPT, effectively captures three of the five parameterizing quantiles, while the Beta distribution only provides an approximation. Finding parameters of Beta distribution requires an optimization step.</p>
<p>The J-QPD-S distribution is a semi-bounded variant of the distribution that employs exponentiated hyperbolic arcsine transformations of the Johnsonâs SU quantile function <span class="citation" data-cites="hadlock2017JohnsonQuantileParameterizedDistributions">(<a href="#ref-hadlock2017JohnsonQuantileParameterizedDistributions" role="doc-biblioref">Hadlock and Bickel, 2017</a>)</span></p>
<p><span class="math display">\[
\begin{gathered}
Q_S(u\vert q_1, q_2, q_3, \alpha)=\begin{cases}
l_b+\theta\exp\left(\lambda\sinh\left(\sinh^{-1}(\delta S(u))+\sinh^{-1}(nc\delta)\right)\right), \quad &amp;n \neq 0\\
l_b+\theta\exp\left(\lambda\delta S(u)\right), \quad &amp;n=0
\end{cases}
\end{gathered}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\begin{gathered}
S(u)=\Phi^{-1}(u); \quad c=S(1-\alpha);\\
L=\ln(q_1-l_b); \quad  B=\ln(q_2-l_b);\\
H=\ln(q_3-l_b); \quad n=\text{sgn}(L+H-2B)\\
\theta=\begin{cases}
q_1-l_b, \quad n=1,\\
q_2-l_b, \quad n=0,\\
q_3-l_b, \quad n=-1,\end{cases}\\
\delta=\frac{1}{c}\sinh\left(\cosh^{-1}\left(\frac{H-L}{2\min(B-L,H-B)}\right)\right)\\
\lambda=\frac{1}{\delta c}\min(H-B, B-L)
\end{gathered}
\]</span></p>
<p>When <span class="math inline">\(n=\text{sgn}(L+H-2B)\)</span> evaluates to zero, he resulting distribution is a lognormal distribution with parameters <span class="math inline">\(\mu=\ln(\theta)=\ln(q_2-l_b)\)</span> and <span class="math inline">\(\sigma=\lambda\delta=(H-B)/c\)</span>. This distribution has support on the interval <span class="math inline">\([l_b,\infty]\)</span>.</p>
<p>The right panel in <a href="#fig-jqpd1" class="quarto-xref">Figure&nbsp;2</a> depicts the J-QPD-S quantile function, which is parameterized using 0.25-SPT and 0.01-SPT assessments of the total trade flow for citrus fruit imported by the EU from Indonesia, Malaysia, Thailand, and Vietnam in tons/year <span class="citation" data-cites="efsa2023RiskAssessmentCitripestis">(<a href="#ref-efsa2023RiskAssessmentCitripestis" role="doc-biblioref">EFSA et al., 2023</a>)</span>.</p>
</section>
<section id="generalisations-of-qpds" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="generalisations-of-qpds"><span class="header-section-number">3.3</span> Generalisations of QPDs</h2>
<section id="generalized-johnson-quantile-parameterized-distribution" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="generalized-johnson-quantile-parameterized-distribution"><span class="header-section-number">3.3.1</span> Generalized Johnson Quantile-Parameterized Distribution</h3>
<p>Hadlock and Bickel <span class="citation" data-cites="hadlock2019GeneralizedJohnsonQuantileParameterized">(<a href="#ref-hadlock2019GeneralizedJohnsonQuantileParameterized" role="doc-biblioref">Hadlock and Bickel, 2019</a>)</span> introduced the <em>generalized</em> version of the Johnson Quantile-Parameterized distribution system, denoted as G-QPD, by replacing the Normal distribution in the core of the Johnson SU quantile function with the quantile functions of the logistic and Cauchy distributions.</p>
<p>The generalized quantile function (QF) shares similarities with the probit-based distribution described earlier, with <span class="math inline">\(S(u)\)</span> defined as the quantile function of either the logistic or Cauchy distribution.</p>
<p>The standard quantile function and distribution function of the logistic distribution are given by:</p>
<p><span class="math display">\[
S(u)= \ln\left(\frac{u}{1-u}\right);\quad S^{-1}(y)=[\exp(-y)+1]^{-1}
\]</span></p>
<p>The standard quantile function and distribution function of the Cauchy distribution are given by:</p>
<p><span class="math display">\[
S(u)= \tan\left[\pi\left(u-\frac{1}{2}\right)\right];\quad S^{-1}(y)=\frac{1}{ \pi}\arctan(y)+\frac{1}{2}
\]</span></p>
<p>Hadlock and Bickel <span class="citation" data-cites="hadlock2019GeneralizedJohnsonQuantileParameterized">(<a href="#ref-hadlock2019GeneralizedJohnsonQuantileParameterized" role="doc-biblioref">Hadlock and Bickel, 2019</a>)</span> show that the <em>kernel</em> quantile function <span class="math inline">\(S(u)\)</span> can be any standardized (<span class="math inline">\(S(0.5)=0\)</span>), symmetrical (<span class="math inline">\(s(u)=s(1-u)\)</span>), and unbounded (<span class="math inline">\(S(u)\in(-\infty;\infty)\)</span>) quantile function with a smooth quantile density <span class="math inline">\(dS(u)/du=s(u)\)</span>. The authors further showed that if <span class="math inline">\(S(u)\)</span> and <span class="math inline">\(S^{-1}(y)\)</span> are expressible in closed-form, the quantile function and distribution function of G-QPD will also be closed-form.</p>
<p>For the <em>logistic</em> kernel, the G-QPD-S represents the generalized log-logistic distribution, characterized by two shape parameters, <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\delta\)</span>. For the Cauchy kernel, the G-QPD-S corresponds to the shifted log-Cauchy distribution <span class="citation" data-cites="hadlock2019GeneralizedJohnsonQuantileParameterized">(<a href="#ref-hadlock2019GeneralizedJohnsonQuantileParameterized" role="doc-biblioref">Hadlock and Bickel, 2019</a>)</span>.</p>
</section>
<section id="sec-genmyerson" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="sec-genmyerson"><span class="header-section-number">3.3.2</span> Generalized Myerson distributions</h3>
<p>Following the approach in Hadlock and Bickel <span class="citation" data-cites="hadlock2019GeneralizedJohnsonQuantileParameterized">(<a href="#ref-hadlock2019GeneralizedJohnsonQuantileParameterized" role="doc-biblioref">Hadlock and Bickel, 2019</a>)</span>, Myerson distribution can be generalized by substituting the Normal kernel quantile function <span class="math inline">\(S(u)=\Phi^{-1}(u)\)</span> with an alternative symmetrical quantile function based on the depth <span class="math inline">\(u\)</span>. Below, we discuss possible kernels and the resulting distributions:</p>
<p><strong>Logit-Myerson distribution</strong>. Recently Wilson et al <span class="citation" data-cites="wilson2023ReconciliationExpertPriors">(<a href="#ref-wilson2023ReconciliationExpertPriors" role="doc-biblioref">Wilson et al., 2023</a>)</span> reparameterized <em>log-logistic distribution</em> in terms of a Symmetric Percentile Triplet. Even though the authors do not recognize it as such, the resulting quantile-parameterized distribution is a Myerson distribution with logit kernel QF <span class="math inline">\(S(u)=\ln\left(\frac{u}{1-u}\right)\)</span>).</p>
<p>There could be several reasons why one might prefer the logit function over the probit function <span class="citation" data-cites="berkson1951WhyPreferLogits">(<a href="#ref-berkson1951WhyPreferLogits" role="doc-biblioref">Berkson, 1951</a>)</span>. For example, distribution based on logit may exhibit greater numerical stability due to its simple closed-form quantile function, which does not rely on numerical approximation during sampling. Logit-Myerson distribution displays slightly heavier tails compared to the standard (probit-based) Myerson distribution (<a href="#fig-gmyerson-qfdqf-plot1" class="quarto-xref">Figure&nbsp;3</a>).</p>
<p><strong>Sech-Myerson distribution</strong>. Following the same principle adopted by Wilson et al. <span class="citation" data-cites="wilson2023ReconciliationExpertPriors">(<a href="#ref-wilson2023ReconciliationExpertPriors" role="doc-biblioref">Wilson et al., 2023</a>)</span> a variant of Myerson distribution may be created using the hyperbolic secant quantile function:</p>
<p><span class="math display">\[
S(u)=\ln\left[\tan\left(\frac{\pi}{2}u\right)\right]
\]</span></p>
<p>The Sech-Myerson distribution possesses thicker tails than the Logit-Myerson distribution for the same parameterizing SPT <span class="math inline">\(\{-5,4,16, 0.25\}\)</span> (<a href="#fig-gmyerson-qfdqf-plot1" class="quarto-xref">Figure&nbsp;3</a>). In <a href="#sec-compareqf" class="quarto-xref">Section&nbsp;3.8</a>, we conduct a comparative analysis of different variations of the Generalized Myerson distribution alongside their parametric counterparts and other quantile distributions.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-gmyerson-qfdqf-plot1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gmyerson-qfdqf-plot1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="qpppp_files/figure-html/fig-gmyerson-qfdqf-plot1-1.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gmyerson-qfdqf-plot1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Quantile function and quantile density of Generalized Myerson Distributions
</figcaption>
</figure>
</div>
</div>
</div>
<p>Theoretically, there is an infinite range of quantile function (QF) kernels that can be utilized to generate new variations of the Generalized Myerson distribution. These candidate kernel distributions can even include shape parameters, as long as the resulting <span class="math inline">\(S(u)\)</span> remains standardized, symmetrical, and unbounded, as specified above. For instance, it is possible to incorporate the basic QF of the Tukey Lambda distribution <span class="math inline">\(S(u\vert\lambda)=u^\lambda-(1-u)^\lambda\)</span> for a fixed <span class="math inline">\(\lambda \neq 0\)</span>, or the Cauchy distribution <span class="math inline">\(S(u)=\tan[\pi(u-0.5)]\)</span>, as employed by <span class="citation" data-cites="hadlock2019GeneralizedJohnsonQuantileParameterized">(<a href="#ref-hadlock2019GeneralizedJohnsonQuantileParameterized" role="doc-biblioref">Hadlock and Bickel, 2019</a>)</span>. However, it is important to note that not all standard quantile functions are created equal. To illustrate the issue of unreliable kernels, let us consider Myerson distributions based on the Cauchy and Tukey Lambda quantile functions (for <span class="math inline">\(\lambda=-0.5\)</span>). As can be observed in <a href="#fig-gmyerson-qfdqf-plot2" class="quarto-xref">Figure&nbsp;4</a>, the density of Generalized Myerson distribution with these kernels exhibits unexpected spike near the lower bound.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-gmyerson-qfdqf-plot2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gmyerson-qfdqf-plot2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="qpppp_files/figure-html/fig-gmyerson-qfdqf-plot2-1.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gmyerson-qfdqf-plot2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Quantile function and quantile density of Generalized Myerson Distributions with unreliable kernels
</figcaption>
</figure>
</div>
</div>
</div>
<p>While all right-skewed Generalized Myerson distributions are bounded on the left at <span class="math inline">\(\lim_{u\rightarrow0}Q(u\vert\theta)=q_2-\rho\frac{1}{\beta-1}\)</span> regardless of the kernel used, the quantile density at the left limit <span class="math inline">\(\lim_{u\rightarrow0}[q(u\vert\theta)]^{-1}\)</span> is not independent of the kernel. Although we can assume that <span class="math inline">\(q(0)=\infty\)</span>, the lower tail of the density quantile function <span class="math inline">\([q(u)]^{-1}\)</span> may exhibit a curling effect for certain kernels, resulting in an increase in density for lower values of <span class="math inline">\(u\)</span>. This effect is caused by the non-monotonic behavior of the quantile convexity function <span class="math inline">\(c(u)=dq(u)/du\)</span>. This can be easily verified by taking the second derivative of <span class="math inline">\(\beta^{S(u)}\)</span> for <span class="math inline">\(\beta&gt;0\)</span>. While such kernels are mathematically valid and yield a non-decreasing Generalized Myerson QF, we believe that they may be less useful due to the counter-intuitive concentration of density in the bounded tail. Consequently, we do not recommend using Cauchy or Tukey Lambda kernels in practical applications.</p>
</section>
</section>
<section id="simple-q-normal-metalog-distributions" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="simple-q-normal-metalog-distributions"><span class="header-section-number">3.4</span> Simple Q-Normal, Metalog distributions</h2>
<p>An alternative system of quantile-parameterized distributions was proposed by Keelin and Powley <span class="citation" data-cites="keelin2011QuantileParameterizedDistributions powley2013QuantileFunctionMethods">(<a href="#ref-keelin2011QuantileParameterizedDistributions" role="doc-biblioref">Keelin and Powley, 2011</a>; <a href="#ref-powley2013QuantileFunctionMethods" role="doc-biblioref">Powley, 2013</a>)</span>. This approach relies on the finite Taylor expansion of parameters in the standardized quantile functions. Within this framework, two distributions were introduced: the Simple Q-Normal distribution and the Metalog distribution.</p>
<p>The Simple Q-Normal (SQN) distribution was developed by expanding the parameters in the normal quantile function. Keelin et al.&nbsp;(2011) used this method to express the parameters of the normal quantile function <span class="math inline">\(Q(u\vert\mu,\sigma)=\mu+\sigma z(u)\)</span> as linear functions of the depth <span class="math inline">\(u\)</span>. Specifically, <span class="math inline">\(\mu(u)=a_1+a_4u\)</span> and <span class="math inline">\(\sigma(u)=a_2+a_3u\)</span>, where <span class="math inline">\(z(u)=\Phi^{-1}(u)\)</span> denotes the standard normal quantile function. Therefore, the quantile function of the SQN distribution can be expressed as follows:</p>
<p><span id="eq-SQNQF"><span class="math display">\[
Q(u)= a_1+a_2z(u)+a_3uz(u)+a_4u\\
\tag{1}\]</span></span></p>
<p>where <span class="math inline">\(z(u)=\Phi^{-1}(u)\)</span>, and <span class="math inline">\(a=\{a_1,a_2,a_3, a_4\}\)</span> represents a vector of parameters.</p>
<p>Consider a quantile-probability tuple of size 4, denoted as <span class="math inline">\(\{\mathbf{p}, \mathbf{q}\}_4\)</span>, which consists of an ordered vector of cumulative probabilities <span class="math inline">\(\mathbf{p}=\{p_1,p_2,p_3, p_4\}\)</span> and an ordered vector of corresponding quantiles <span class="math inline">\(\mathbf{q}=\{q_1,q_2,q_3, q_4\}\)</span>. Substituting these vectors into the SQN quantile function for <span class="math inline">\(u\)</span> and <span class="math inline">\(Q(u)\)</span>, respectively, we obtain the following matrix equation:</p>
<p><span id="eq-sqn-matrix"><span class="math display">\[
\mathbf{q}=\mathbb Pa
\tag{2}\]</span></span></p>
<p>where</p>
<p><span class="math display">\[
\begin{gathered}
\mathbb P=\begin{bmatrix} 1 &amp; z(p_1) &amp; p_1z(p_1) &amp; p_1\\
                1 &amp; z(p_2) &amp; p_2z(p_2) &amp; p_2\\
                1 &amp; z(p_3) &amp; p_3z(p_3) &amp; p_3\\
                1 &amp; z(p_4) &amp; p_4z(p_4) &amp; p_4\end{bmatrix}
\end{gathered}
\]</span></p>
<p>and <span class="math inline">\(a=\{a_1, a_2, a_3, a_4\}\)</span> represents the parameter vector of the SQN distribution.</p>
<p>The parameter vector <span class="math inline">\(a\)</span> can be obtained by solving the matrix <a href="#eq-sqn-matrix" class="quarto-xref">Equation&nbsp;2</a>, given the 4-element quantile-probability tuple <span class="math inline">\(\{\mathbf{p}, \mathbf{q}\}_4\)</span> <span class="citation" data-cites="keelin2011QuantileParameterizedDistributions perepolkin2021HybridElicitationIndirect">(<a href="#ref-keelin2011QuantileParameterizedDistributions" role="doc-biblioref">Keelin and Powley, 2011</a>; <a href="#ref-perepolkin2021HybridElicitationIndirect" role="doc-biblioref">Perepolkin et al., 2021</a>)</span>.</p>
<p>The same approach was later employed by <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span> in creating the metalog (meta-logistic) distribution. Starting with the quantile function of the logistic distribution <span class="math inline">\(Q(u\vert\mu,s)=\mu+s\text{logit}(u)\)</span>, where <span class="math inline">\(\mu\)</span> corresponds to the mean and <span class="math inline">\(s\)</span> is proportional to the standard deviation <span class="math inline">\(\sigma=s\pi/\sqrt3\)</span>, <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span> expanded the parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(s\)</span> using a finite Taylor series centered at 0.5. Specifically, <span class="math inline">\(\mu(u)=a_1+a_4(u-0.5)+a_5(u-0.5)^2+\dots\)</span> and <span class="math inline">\(s(u)=a_2+a_3(u-0.5)+a_6(u-0.5)^2+\dots\)</span>, where <span class="math inline">\(a_i, \; i = \{1,2,\dots,n\}\)</span> are real constants.</p>
<p>Therefore, the metalog quantile function is:</p>
<p><span class="math display">\[
Q(u)= a_1+a_2\text{logit}(u)+a_3(u-0.5)\text{logit}(u)+a_4(u-0.5)+a_5(u-0.5)^2\cdots,
\]</span></p>
<p>Given a QPT of size <span class="math inline">\(m\)</span> denoted by <span class="math inline">\(\{\mathbf{p}, \mathbf{q}\}_m\)</span>, where <span class="math inline">\(\mathbf{p}\)</span> and <span class="math inline">\(\mathbf{q}\)</span> are ordered vectors of cumulative probabilities and corresponding quantiles, respectively, the vector of coefficients <span class="math inline">\(\mathbf{a}={a_1,\dots,a_m}\)</span> can be determined by solving the matrix equation <span class="math inline">\(\mathbf{q}=\mathbb{P}\mathbf{a}\)</span>, where <span class="math inline">\(\mathbf{p}\)</span>, <span class="math inline">\(\mathbf{q}\)</span>, and <span class="math inline">\(\mathbf{a}\)</span> are column vectors, and <span class="math inline">\(\mathbb{P}\)</span> is an <span class="math inline">\(m \times n\)</span> matrix:</p>
<p><span id="eq-metalogPMatrixeq"><span class="math display">\[
\begin{gathered}
\mathbb{P} = \left[\begin{array}{lllll}
1  &amp;\text{logit}(p_1) &amp;(p_1-0.5)\text{logit}(p_1) &amp;(p_1-0.5) &amp;\cdots\\
1  &amp;\text{logit}(p_2) &amp;(p_2-0.5)\text{logit}(p_2) &amp;(p_2-0.5) &amp;\cdots\\
   &amp;                  &amp;\vdots\\
1  &amp;\text{logit}(p_m) &amp;(p_m-0.5)\text{logit}(p_m) &amp;(p_m-0.5) &amp;\cdots
\end{array}\right]
\end{gathered}
\tag{3}\]</span></span></p>
<p>The vector of coefficients <span class="math inline">\(\mathbf{a}\)</span> can be determined as <span class="math inline">\(\mathbf{a}=[\mathbb{P}^{T}\mathbb{P}]^{-1}\mathbb{P}^{T}\mathbf{q}\)</span>. If <span class="math inline">\(\mathbb{P}\)</span> is a square matrix, meaning the number of terms <span class="math inline">\(n\)</span> is equal to the size of the parameterizing QPT <span class="math inline">\(m\)</span>, the equation can be further simplified to <span class="math inline">\(\mathbf{a}=\mathbb{P}^{-1}\mathbf{q}\)</span>. Metalog is said to be <em>approximated</em> when the number of quantile-probability pairs used for parameterization exceeds the number of terms in the metalog QF <span class="citation" data-cites="keelin2016MetalogDistributions perepolkin2021HybridElicitationIndirect">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>; <a href="#ref-perepolkin2021HybridElicitationIndirect" role="doc-biblioref">Perepolkin et al., 2021</a>)</span>.</p>
<p>The SQN and Metalog distributions are families of extended distributions that, in theory, can have an arbitrary number of terms. Keelin <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span> demonstrated the flexibility of the metalog distribution and its ability to approximate arbitrarily complex probability density functions with high precision, given enough terms in the metalog specification. In practice, 10-15 terms are sufficient to approximate the distributional shapes of virtually any complexity <span class="citation" data-cites="keelin2021MetalogDistributionsVirtually">(<a href="#ref-keelin2021MetalogDistributionsVirtually" role="doc-biblioref">Keelin and Howard, 2021</a>)</span>. Keelin <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span> introduced the bounded logit-metalog, the semi-bounded log-metalog, and a special case of a 3-term metalog parameterized by <span class="math inline">\(\alpha\)</span>-SPT (SPT-metalog).</p>
<p>However, not all combinations of parameters <span class="math inline">\(\mathbf{a}\)</span> in metalog and SQN distributions result in a feasible (non-decreasing) quantile function. For an arbitrary <span class="math inline">\(\mathbf{a}\)</span>-vector, feasibility must be checked <span class="citation" data-cites="keelin2011QuantileParameterizedDistributions">(<a href="#ref-keelin2011QuantileParameterizedDistributions" role="doc-biblioref">Keelin and Powley, 2011</a>)</span>. In the case of 3-term metalogs, the feasibility conditions are straightforward <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span>. But as the number of terms increases, such conditions become increasingly complex <span class="citation" data-cites="keelin2017MetalogDistributionsFeasibility">(<a href="#ref-keelin2017MetalogDistributionsFeasibility" role="doc-biblioref">Keelin, 2017</a>)</span>. Having to deal with such feasibility requirements stands in contrast with QFâs that are constructed using Gilchrist rules <a href="#tbl-qf-trans" class="quarto-xref">Table&nbsp;1</a>, which guarantee feasibility.</p>
</section>
<section id="quantile-mixtures" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="quantile-mixtures"><span class="header-section-number">3.5</span> Quantile mixtures</h2>
<p>Recently <span class="citation" data-cites="peng2023MixtureQuantilesEstimated">(<a href="#ref-peng2023MixtureQuantilesEstimated" role="doc-biblioref">Peng et al., 2023</a>)</span> proposed a novel framework for extended quantile-parameterized distributions based on quantile mixtures (not to be confused with CDF/PDF mixtures, <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000, p. 107</a>)</span>). They introduced a formulation in which a QPD quantile function is expressed as a linear combination of <span class="math inline">\(I\)</span> standardized quantile functions, following Gilchristâs <em>linear combination rule</em> (<a href="#tbl-qf-trans" class="quarto-xref">Table&nbsp;1</a>):</p>
<p><span class="math display">\[
G(u\vert\theta)=\sum_{i=0}^I\theta_iQ_i(u)
\]</span></p>
<p>Here, <span class="math inline">\(Q_i(u)\)</span> represent basis quantile functions for the random variable <span class="math inline">\(Y\)</span> with <span class="math inline">\(Q_0(u)=1\)</span>, and <span class="math inline">\(\pmb\theta=\{\theta_0,\theta_1,\dots,\theta_I\}\)</span> is a non-negative parameter vector that determines the contribution of each QF component in the quantile mixture. To compute the coefficients <span class="math inline">\(\pmb\theta\)</span>, the system of equations is solved</p>
<p><span class="math display">\[
\mathbf q=\mathbb Q \pmb\theta+\pmb\epsilon
\]</span></p>
<p>where <span class="math inline">\(\mathbf{q}=\{q_1,q_2,\dots, q_j\}\)</span> is an ordered vector of <span class="math inline">\(J\)</span> parameterizing quantiles, corresponding to an ordered vector of cumulative probabilities <span class="math inline">\(\mathbf{p}=\{p_1,p_2,\dots, p_j\}\)</span>, <span class="math inline">\(\pmb\theta\)</span> is a non-negative vector of <span class="math inline">\(I+1\)</span> parameters, <span class="math inline">\(\pmb\epsilon\)</span> is a <span class="math inline">\(J\)</span>-size vector of errors to be minimized, and <span class="math inline">\(\mathbb Q\)</span> is a <span class="math inline">\(J\times(I+1)\)</span> matrix of regression factors</p>
<p><span class="math display">\[
\begin{gathered}
\mathbb{Q} = \left[\begin{array}{lllll}
1  &amp;Q_1(p_1) &amp;Q_2(p_1) &amp;\cdots &amp;Q_I(p_1)\\
1  &amp;Q_1(p_2) &amp;Q_2(p_2) &amp;\cdots &amp;Q_I(p_2)\\
   &amp;\vdots   &amp;\vdots   &amp;\ddots \\
1  &amp;Q_1(p_J) &amp;Q_2(p_J) &amp;\cdots &amp;Q_I(p_J)
\end{array}\right]
\end{gathered}
\]</span></p>
<p>By ensuring non-negativity of weights (<span class="math inline">\(\theta_i\geq0\)</span>), the solution guarantees a proper non-decreasing quantile function. To estimate the values of the vector <span class="math inline">\(\pmb\theta\in\Theta\)</span>, the authors suggest using constrained weighted least squares regression with optional regularization. The authors demonstrated that the estimator <span class="math inline">\(\widehat{\pmb\theta}=\underset{\pmb\theta\in\Theta}{\text{argmin}} \left(\frac{1}{J}\sum_{j=1}^Jw_j\mathcal{E}_q(y_j-Q_j\pmb\theta)\right)^{\frac{1}{q}}\)</span>, <span class="math inline">\(\mathcal{E}_q(x)=\lvert x \rvert^q\)</span>, <span class="math inline">\(w_j&gt;0\)</span>, is asymptotically a q-Wasserstein distance estimator, which converges in distribution to a Normal distribution. The paper <span class="citation" data-cites="peng2023MixtureQuantilesEstimated">(<a href="#ref-peng2023MixtureQuantilesEstimated" role="doc-biblioref">Peng et al., 2023</a>)</span> includes the application of the quantile mixture model using a large number of asymmetric t-distributions, and a quantile mixture of Generalized Beta II distributions.</p>
<p>The quantile mixtures method of creating new QPDs guarantees feasibility by construction, while affording nearly infinite flexibility, provided that the component quantile functions are selected from a wide set of distributions of varying shapes. Besides, a QPD constructed as a linear combination of QFs is guaranteed to be unimodal, unless one of the component in the mixture is multimodal <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(see <a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a> for examples)</span>. In addition, the method proposed by <span class="citation" data-cites="peng2023MixtureQuantilesEstimated">(<a href="#ref-peng2023MixtureQuantilesEstimated" role="doc-biblioref">Peng et al., 2023</a>)</span> offers an advantage of resulting in closed-form quantile function and quantile density function, provided that each of the components can be expressed analytically. Unfortunately, neither asymmetric t-distribution nor Generalized Beta II distribution, used by the authors, has a closed-form QF. However, one can construct a highly flexible quantile function using Gilchrist rules (<a href="#tbl-qf-trans" class="quarto-xref">Table&nbsp;1</a>) or use one of the existing well-studied QFs discussed in the literature. In <a href="#sec-qmexample" class="quarto-xref">Section&nbsp;3.7</a>, we provide an example of using a quantile mixture of diversely-shaped quantile functions to construct a bespoke highly flexible QPD.</p>
</section>
<section id="other-distributions" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="other-distributions"><span class="header-section-number">3.6</span> Other distributions</h2>
<section id="triangular-and-two-sided-power-distributions" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="triangular-and-two-sided-power-distributions"><span class="header-section-number">3.6.1</span> Triangular and Two-Sided Power distributions</h3>
<p>Several other distributions with at least some parameters mapped to quantiles were proposed, including the reparameterization of the Generalized Lambda Distribution by <span class="citation" data-cites="chalabi2012FlexibleDistributionModeling">(<a href="#ref-chalabi2012FlexibleDistributionModeling" role="doc-biblioref">Chalabi et al., 2012</a>)</span> and the quantile-parameterized triangular (two-sided power) distribution by <span class="citation" data-cites="kotz2004BetaOtherContinuous">(<a href="#ref-kotz2004BetaOtherContinuous" role="doc-biblioref">Kotz and Van Dorp, 2004</a>)</span>.</p>
<p>Kotz and van Dorp <span class="citation" data-cites="kotz2004BetaOtherContinuous">(<a href="#ref-kotz2004BetaOtherContinuous" role="doc-biblioref">Kotz and Van Dorp, 2004</a>)</span> describe the quantile-parameterized version of the triangular distribution <span class="citation" data-cites="johnson1997TriangularDistributionProxy">(<a href="#ref-johnson1997TriangularDistributionProxy" role="doc-biblioref">Johnson, 1997</a>)</span>. This bounded distribution is widely used in the finance and insurance industry and is popularized by the @Risk software package, developed by Palisade <span class="citation" data-cites="palisadecorporation2009GuideUsingRISK">(<a href="#ref-palisadecorporation2009GuideUsingRISK" role="doc-biblioref">Palisade Corporation, 2009</a>)</span>. The triangular distribution is parameterized by the two quantiles <span class="math inline">\(q_{a}\)</span> and <span class="math inline">\(q_{b}\)</span>, and the mode <span class="math inline">\(m\)</span>, subject to the constraint that <span class="math inline">\(a\leq q_a\leq m\leq q_b\leq b\)</span>, where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> represent the lower and upper bounds, respectively. The standard quantile function for the triangular distribution is expressed in terms of the bounds <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and the mode <span class="math inline">\(m\)</span>.</p>
<p><span class="math display">\[
\begin{gathered}
Q(u\vert a,m,b)=\begin{cases}
a+\sqrt{u(m-a)(b-a)}, &amp;\quad \text{for } 0\leq u \leq\frac{m-a}{b-a}\\
b-\sqrt{(1-u)(b-m)(b-a)}, &amp;\quad \text{for } \frac{m-a}{b-a}\leq u \leq 1
\end{cases}
\end{gathered}
\]</span></p>
<p>In <span class="citation" data-cites="kotz2004BetaOtherContinuous">(<a href="#ref-kotz2004BetaOtherContinuous" role="doc-biblioref">Kotz and Van Dorp, 2004</a>)</span> the authors show that given the two parameterizing quantile-probability pairs <span class="math inline">\({q_a,p_a}\)</span> and <span class="math inline">\({q_b,p_b}\)</span> and the mode value <span class="math inline">\(m\)</span>, there exists a unique value of depth <span class="math inline">\(p_a&lt;p&lt;p_b\)</span> corresponding to the root of the function</p>
<p><span class="math display">\[
g(p)=\frac{(m-q_a)(1-\sqrt{\frac{1-p_b}{1-p}})}{(q_b-m)(1-\sqrt{\frac{p_a}{p}})+(m-q_a)(1-\sqrt{\frac{1-p_b}{1-p}})}-p
\]</span></p>
<p>The root value <span class="math inline">\(p\in (p_a,p_b)\)</span> of the function <span class="math inline">\(g(p)\)</span> can be found using any of the bracketing root-finding algorithms <span class="citation" data-cites="perepolkin2023TenetsQuantilebasedInference">(<a href="#ref-perepolkin2023TenetsQuantilebasedInference" role="doc-biblioref">Perepolkin et al., 2023</a>)</span>. It can then be substituted into the following expressions to find the lower <span class="math inline">\(a\)</span> and upper <span class="math inline">\(b\)</span> limit parameters of the triangular distribution:</p>
<p><span class="math display">\[
\begin{gathered}
a(p) \equiv \frac{q_a-m\sqrt{\frac{p_a}{p}}}{1-\sqrt{\frac{p_a}{p}}}, \quad a(p)&lt;q_a\\
b(p) \equiv \frac{q_b-m\sqrt{\frac{1-p_b}{1-p}}}{1-\sqrt{\frac{1-p_b}{1-p}}}, \quad b(p)&gt;q_b
\end{gathered}
\]</span></p>
<p>The book <span class="citation" data-cites="kotz2004BetaOtherContinuous">(<a href="#ref-kotz2004BetaOtherContinuous" role="doc-biblioref">Kotz and Van Dorp, 2004</a>)</span> provides an algorithm for fitting a four-parameter generalization of the triangular distribution called the Two-Sided Power Distribution (TSP), using three quantile-probability pairs and a mode value. For more information on fitting the Quantile-Parameterized TSP Distribution by quantiles, refer to Section 4.3.3 of <span class="citation" data-cites="kotz2004BetaOtherContinuous">(<a href="#ref-kotz2004BetaOtherContinuous" role="doc-biblioref">Kotz and Van Dorp, 2004</a>)</span>.</p>
</section>
<section id="sec-gld" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="sec-gld"><span class="header-section-number">3.6.2</span> Generalized Lambda Distribution</h3>
<p>Chalabi, Scott and WÃ¼rtz (CSW) <span class="citation" data-cites="chalabi2012FlexibleDistributionModeling">(<a href="#ref-chalabi2012FlexibleDistributionModeling" role="doc-biblioref">Chalabi et al., 2012</a>)</span> proposed an asymmetry-steepness reparameterization of the Generalized Lambda Distribution (GLD) <span class="citation" data-cites="freimer1988StudyGeneralizedTukey">(<a href="#ref-freimer1988StudyGeneralizedTukey" role="doc-biblioref">Freimer et al., 1988</a>)</span> with four parameters. This reparameterization involves mapping the location to the median and the scale to the interquartile range (IQR), which corresponds to the first and second robust moments <span class="citation" data-cites="kim2004MoreRobustEstimation moors1988QuantileAlternativeKurtosis">(<a href="#ref-kim2004MoreRobustEstimation" role="doc-biblioref">Kim and White, 2004</a>; <a href="#ref-moors1988QuantileAlternativeKurtosis" role="doc-biblioref">Moors, 1988</a>)</span>.</p>
<p>The reparameterized Generalized Lambda Distribution (CSW GLD) has a quantile function given by</p>
<p><span class="math display">\[
Q(u\vert\tilde\mu,\tilde\sigma,\chi,\xi)=\tilde\mu+\tilde\sigma\frac{S\left(u\vert\chi,\xi\right)-S\left(\frac{1}{2}\vert\chi,\xi\right)}{S\left(\frac{3}{4}\vert\chi,\xi\right)-S\left(\frac{1}{4}\vert\chi,\xi\right)}
\]</span></p>
<p>where <span class="math inline">\(\tilde\mu,\tilde\sigma,\chi,\xi\)</span> represent the location, scale, asymmetry, and steepness parameters, respectively. The specific form of the basic function <span class="math inline">\(S(u)\)</span> depends on the values of the parameters <span class="math inline">\(\chi\)</span> and <span class="math inline">\(\xi\)</span></p>
<p><span class="math display">\[
S(u\vert\chi,\xi)=
\begin{cases}
\begin{aligned}
&amp;\ln(u)-\ln(1-u),  \quad \text{if }\chi=0,\xi=0.5&amp;\\
&amp;\ln(u)-\frac{1}{2\alpha}\left[(1-u)^{2\alpha}-1\right], \quad \text{if }\chi\neq0,\xi=\frac{1}{2}(1+\chi)&amp;\\
&amp;\frac{1}{2\beta}\left[u^{2\beta}-1\right]-\ln(1-u), \quad \text{if }\chi\neq0,\xi=\frac{1}{2}(1-\chi)&amp;\\
&amp;\frac{1}{\alpha+\beta}\left[u^{\alpha+\beta}-1\right]-\frac{1}{\alpha-\beta}\left[(1-u)^{\alpha-\beta}-1\right], \quad \text{otherwise}
\end{aligned}
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\alpha=0.5\frac{0.5-\xi}{\sqrt{\xi(1-\xi)}}\)</span> and <span class="math inline">\(\beta=0.5\frac{\chi}{\sqrt{1-\chi^2}}\)</span>. The bounds of the distribution are given by</p>
<p><span class="math display">\[
\begin{gathered}
S(0\vert\chi,\xi)=\begin{cases}
\begin{aligned}
&amp;-\frac{1}{\alpha+\beta},\quad &amp;\text{if }\xi&lt;\frac{1}{2}(1+\chi)\\
&amp;-\infty, \quad &amp;\text{otherwise}
\end{aligned}
\end{cases}\\
S(1\vert\chi,\xi)=\begin{cases}
\begin{aligned}
&amp;\frac{1}{\alpha-\beta},\quad &amp;\text{if }\xi&lt;\frac{1}{2}(1-\chi)\\
&amp;\infty, \quad &amp;\text{otherwise}
\end{aligned}
\end{cases}
\end{gathered}
\]</span></p>
<p>The CSW GLD can have unbounded, bounded, and semi-bounded support, accommodating a wide range of shapes, including unimodal, monotone, U-shaped, and S-shaped densities <span class="citation" data-cites="chalabi2012FlexibleDistributionModeling">(<a href="#ref-chalabi2012FlexibleDistributionModeling" role="doc-biblioref">Chalabi et al., 2012</a>)</span>. Although the CSW GLD is not strictly parameterized by quantiles, the mapping of the location and scale parameters to the median and IQR makes it a suitable candidate for expert-informed distribution specification.</p>
<p>Several specialized methods have been developed for fitting the GLD to samples <span class="citation" data-cites="karian2003ComparisonGLDFitting">(<a href="#ref-karian2003ComparisonGLDFitting" role="doc-biblioref">Karian and Dudewicz, 2003</a>)</span>. The parameterization of the CSW GLD simplifies the fitting process because two of the four parameters can be directly calculated from the sample: the location parameter is equal to the sample median, and the scale parameter is equal to the interquartile range. The remaining parameters can be estimated using various methods, including robust moment matching, quantile matching, trimmed L-moments, distributional least squares/absolutes, as well as maximum likelihood estimation <span class="citation" data-cites="chalabi2012FlexibleDistributionModeling gilchrist2000StatisticalModellingQuantile">(<a href="#ref-chalabi2012FlexibleDistributionModeling" role="doc-biblioref">Chalabi et al., 2012</a>; <a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>)</span>. The range of feasible values for the steepness and asymmetry parameters can be further reduced with the shape conditions specified in Section 3.5 of <span class="citation" data-cites="chalabi2012FlexibleDistributionModeling">(<a href="#ref-chalabi2012FlexibleDistributionModeling" role="doc-biblioref">Chalabi et al., 2012</a>)</span>.</p>
<p>Recently, <span class="citation" data-cites="dedduwakumara2021EfficientEstimatorParameters">(<a href="#ref-dedduwakumara2021EfficientEstimatorParameters" role="doc-biblioref">Dedduwakumara et al., 2021</a>)</span> proposed a new method of matching the shape of the GLD distribution to data using the probability density quantile (pdQ) function <span class="citation" data-cites="staudte2017ShapesThingsCome">(<a href="#ref-staudte2017ShapesThingsCome" role="doc-biblioref">Staudte, 2017</a>)</span>. For the quantile function <span class="math inline">\(Q(v), \; v\in [0,1]\)</span> and the corresponding density quantile function <span class="math inline">\(f(Q(v))=[q(v)]^{-1}\)</span>, the pdQ is defined as</p>
<p><span class="math display">\[
f^*(v)=\frac{f(Q(v))}{E\left[f(Q(v))\right]}
\]</span></p>
<p>The probability density quantile function is defined on the unit square and is independent of the location and scale parameters.</p>
<p>Since integrating the GLD density quantile function is difficult, <span class="citation" data-cites="staudte2017ShapesThingsCome">(<a href="#ref-staudte2017ShapesThingsCome" role="doc-biblioref">Staudte, 2017, sec. 2.2</a>)</span>, proposed using the kernel density method to estimate the empirical QDF and, thus, an empirical pdQ for samples from continuous distributions. Fitting the CSW GLD to a sample can be reduced to finding the asymmetry and steepness parameters that minimize</p>
<p><span class="math display">\[
\underset{\chi,\xi}{\text{argmin}}\int_0^1\left[f^*(v, \chi, \xi)-f_{e}^*(v)\right]^2du
\]</span></p>
<p>where <span class="math inline">\(f^*(v,\chi,\xi)\)</span> is the pdQ of the CSW GLD, and <span class="math inline">\(f^*_e(v)\)</span> is the empirical pdQ of the sample. The authors <span class="citation" data-cites="dedduwakumara2021EfficientEstimatorParameters">(<a href="#ref-dedduwakumara2021EfficientEstimatorParameters" role="doc-biblioref">Dedduwakumara et al., 2021</a>)</span> suggest approximating the integral by a discrete set of depths <span class="math inline">\(v\)</span>, replacing the integral with a sum.</p>
</section>
</section>
<section id="sec-qmexample" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="sec-qmexample"><span class="header-section-number">3.7</span> Example</h2>
<p>As an illustration of a faithful approximation of a large number of quantile-probability pairs by QPD, we take 4000 posterior samples (4 chains of 1000 samples each) of one of the random intercepts in the Eight Schools example model included in the <code>cmdstanr</code> package <span class="citation" data-cites="gabry2022CmdstanrInterfaceCmdStan">(<a href="#ref-gabry2022CmdstanrInterfaceCmdStan" role="doc-biblioref">Gabry and ÄeÅ¡novar, 2022</a>)</span> in R. The Eight Schools problem <span class="citation" data-cites="rubin1981EstimationParallelRandomized">(<a href="#ref-rubin1981EstimationParallelRandomized" role="doc-biblioref">Rubin, 1981</a>)</span> measuring the effectiveness of SAT coaching program in 8 US schools is often used as an example model in introductory classes on Bayesian Statistics. In <code>cmdstanr</code> it is modeled using a hierarchical Bayesian model with normal priors for each of the 8 random intercepts <code>theta</code>. However, due to the low number of posterior samples and the heterogeneity in the data, the marginal posterior distributions of the intercept parameters <code>theta</code> deviate from the Gaussian shape in various ways (<a href="#fig-school-thetas" class="quarto-xref">Figure&nbsp;5</a>).</p>
<p>An empirical distribution of posterior samples from a Bayesian model can be viewed as a large number of quantile-probability pairs. Although it is unlikely that such number of quantile-probability pairs could ever be elicitable from an expert (in our case 4000), it could still be of interest to approximate such marginal posterior distribution with a highly flexible quantile function, e.g.&nbsp;for the purpose of posterior passing <span class="citation" data-cites="brand2019CumulativeScienceBayesian pritsker2021ComparingBayesianPosterior">(<a href="#ref-brand2019CumulativeScienceBayesian" role="doc-biblioref">Brand et al., 2019</a>; <a href="#ref-pritsker2021ComparingBayesianPosterior" role="doc-biblioref">Pritsker, 2021</a>)</span>. Closed-form QF expression for the posterior margins would allow reusing it as a prior in a similar model at a later stage. We discuss multivariate extension of this idea in <a href="#sec-multivariateqpd" class="quarto-xref">Section&nbsp;4</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-school-thetas" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-school-thetas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="qpppp_files/figure-html/fig-school-thetas-1.pdf" class="img-fluid" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-school-thetas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Posterior distributions of random interecept parameters <code>theta</code> in the Eight Schools example model <span class="citation" data-cites="gabry2022CmdstanrInterfaceCmdStan">(<a href="#ref-gabry2022CmdstanrInterfaceCmdStan" role="doc-biblioref">Gabry and ÄeÅ¡novar, 2022</a>)</span>
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-fitted-qm" class="quarto-xref">Figure&nbsp;7</a> shows a QPD approximation of the marginal distribution of <code>theta[5]</code> using a quantile mixture of standardized (centered at zero and with the scale parameter set to one) <span class="citation" data-cites="chalabi2012FlexibleDistributionModeling">Chalabi et al. (<a href="#ref-chalabi2012FlexibleDistributionModeling" role="doc-biblioref">2012</a>)</span> Generalized Lambda Distributions (CSW GLD). In order to ensure the diversity of mixture components we generated 400 independent uniformly distributed pairs of the two shape parameters for GLD components using <span class="citation" data-cites="hubbard2019MultiDimensionalCounterBasedPseudo">Hubbard (<a href="#ref-hubbard2019MultiDimensionalCounterBasedPseudo" role="doc-biblioref">2019</a>)</span> pseudo random number generator.</p>
<p>We constructed the matrix <span class="math inline">\(\mathbb Q\)</span> above following the method outlined by <span class="citation" data-cites="peng2023MixtureQuantilesEstimated">Peng et al. (<a href="#ref-peng2023MixtureQuantilesEstimated" role="doc-biblioref">2023</a>)</span> and used Lawson-Hanson non-negative least squares algorithm (implemented in <code>nnls</code> package <span class="citation" data-cites="mullen2023NnlsLawsonhansonAlgorithm">(<a href="#ref-mullen2023NnlsLawsonhansonAlgorithm" role="doc-biblioref">Mullen and van Stokkum, 2023</a>)</span> in R) to find the weights for each of the mixture components. The non-zero elements are shows in <a href="#fig-gld-comp" class="quarto-xref">Figure&nbsp;6</a> along with the weights (which become the scale parameters of the quantile mixture components).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-gld-comp" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gld-comp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="qpppp_files/figure-html/fig-gld-comp-1.pdf" class="img-fluid" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gld-comp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Density functions and quantile functions of GLD components in approximating quantile mixture
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-fitted-qm" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fitted-qm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="qpppp_files/figure-html/fig-fitted-qm-1.pdf" class="img-fluid" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fitted-qm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Distribution of posterior samples approximated by the quantile mixture
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-fitted-qm" class="quarto-xref">Figure&nbsp;7</a> shows the histogram of 4000 parameter values for <code>theta[5]</code> along with the approximation using the quantile mixture with the components shown in <a href="#fig-gld-comp" class="quarto-xref">Figure&nbsp;6</a>. The resulting mixture is a linear combination of GLD quantile functions with a closed form QF and DQF, which makes it possible to reuse this distribution as a quantile-based prior in a Bayesian model <span class="citation" data-cites="perepolkin2023TenetsQuantilebasedInference">(<a href="#ref-perepolkin2023TenetsQuantilebasedInference" role="doc-biblioref">Perepolkin et al., 2023</a>)</span>.</p>
</section>
<section id="sec-compareqf" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="sec-compareqf"><span class="header-section-number">3.8</span> Choosing quantile-parameterized distribution</h2>
<p>A common approach to assess the properties of probability distributions is through central moments, denoted by <span class="math inline">\(\mu_k=\mathbb{E}[(Y-\mu)^k]\)</span>, where <span class="math inline">\(\mu\)</span> represents the expected value of <span class="math inline">\(Y\)</span>. Karl Pearson introduced a classification system for distributions using moment ratios associated with skewness and kurtosis <span class="citation" data-cites="fiori2009KarlPearsonOrigin">(<a href="#ref-fiori2009KarlPearsonOrigin" role="doc-biblioref">Fiori and Zenga, 2009</a>)</span>:</p>
<p><span class="math display">\[
\beta_1=\frac{\mu_3^2}{\mu_2^3},\quad \beta_2=\frac{\mu_4}{\mu_2^2}
\]</span></p>
<p>While computing moments using the quantile function is straightforward (the <span class="math inline">\(n\)</span>-th raw moment is <span class="math inline">\(\mu_k=\int_0^1Q(u)^kdu\)</span>), it may not be possible to calculate higher-order moments for certain distributions.</p>
<p>Alternatively, robust alternatives to moments can be utilized, such as the sample median <span class="math inline">\(\mu_r\)</span>, the interquartile range <span class="math inline">\(\sigma_r\)</span>, the quartile-based robust coefficient of skewness <span class="math inline">\(s_r\)</span> <span class="citation" data-cites="kim2004MoreRobustEstimation">(<a href="#ref-kim2004MoreRobustEstimation" role="doc-biblioref">Kim and White, 2004</a>)</span>, also known as Bowleyâs skewness <span class="citation" data-cites="bowley1920ElementsStatistics">(<a href="#ref-bowley1920ElementsStatistics" role="doc-biblioref">Bowley, 1920</a>)</span> or Galtonâs skewness <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>)</span>, and the octile-based robust coefficient of kurtosis <span class="math inline">\(\kappa_r\)</span>, also known as Moorsâ kurtosis <span class="citation" data-cites="moors1988QuantileAlternativeKurtosis">(<a href="#ref-moors1988QuantileAlternativeKurtosis" role="doc-biblioref">Moors, 1988</a>)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\mu_r=Q(1/2)\\
&amp;\sigma_r=Q(3/4)-Q(1/4)\\
&amp;s_r=\frac{Q(3/4)+Q(1/4)-2Q(1/2)}{\sigma_r}\\
&amp;\kappa_r=\frac{Q(7/8)-Q(5/8)+Q(3/8)-Q(1/8)}{\sigma_r}
\end{aligned}
\]</span></p>
<p><span class="citation" data-cites="kim2004MoreRobustEstimation arachchige2022RobustAnalogsCoefficient">(<a href="#ref-kim2004MoreRobustEstimation" role="doc-biblioref">Kim and White, 2004</a>; <a href="#ref-arachchige2022RobustAnalogsCoefficient" role="doc-biblioref">Arachchige et al., 2022</a>)</span> have proposed to standardize robust moments to facilitate their comparison with the corresponding robust moments of the standard normal distribution. <span class="citation" data-cites="groeneveld1998ClassQuantileMeasures jones2011SkewnessInvariantMeasuresKurtosis">(<a href="#ref-groeneveld1998ClassQuantileMeasures" role="doc-biblioref">Groeneveld, 1998</a>; <a href="#ref-jones2011SkewnessInvariantMeasuresKurtosis" role="doc-biblioref">Jones et al., 2011</a>)</span> have introduced generalizations of robust moments to other quantiles.</p>
<p>Unlike moments, quantiles are always well defined, and since QPDs are parameterized by quantile-probability pairs, quantile-based robust moments can sometimes be directly computed from the parameters. For instance, if the basic quantile function <span class="math inline">\(S(u)\)</span> in <span class="math inline">\(Q(u)=\mu+\sigma S(u)\)</span> is standardized (such that <span class="math inline">\(S(0.5)=0\)</span>), where <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are the location and scale parameters of <span class="math inline">\(Q(u)\)</span> respectively, then <span class="math inline">\(\mu_r=\mu\)</span>. Moreover, <span class="math inline">\(\sigma_r\)</span> is always independent of location, and <span class="math inline">\(s_r\)</span> and <span class="math inline">\(\kappa_r\)</span> are independent of both location and scale.</p>
<p><a href="#fig-unbounded" class="quarto-xref">Figure&nbsp;8</a>, <a href="#fig-semibounded" class="quarto-xref">Figure&nbsp;9</a>, and <a href="#fig-bounded" class="quarto-xref">Figure&nbsp;10</a> resemble the Cullen and Frey <span class="citation" data-cites="cullen1999ProbabilisticTechniquesExposure">(<a href="#ref-cullen1999ProbabilisticTechniquesExposure" role="doc-biblioref">Cullen et al., 1999</a>)</span> plots (Pearson plots), but instead of using central moments, they employ quartile/octile-based robust metrics of skewness <span class="math inline">\(s_r\)</span> and kurtosis <span class="math inline">\(\kappa_r\)</span> to compare the quantile-parameterized distributions to some of their parametric counterparts.</p>
<p>In these plots, Metalog3 and Metalog4 refer to 3- and 4-term metalog distributions, respectively, and GLDcsw refers to Chalabi et al <span class="citation" data-cites="chalabi2012FlexibleDistributionModeling">(<a href="#ref-chalabi2012FlexibleDistributionModeling" role="doc-biblioref">Chalabi et al., 2012</a>)</span> parameterization of GLD. As can be seen in <a href="#fig-unbounded" class="quarto-xref">Figure&nbsp;8</a>, all generalizations of Myerson distributions have higher robust kurtosis for the same robust skewness. Additionally, GLD CSW is more flexible than the unbounded 4-term metalog. The <em>log</em>-transformed metalog distribution appears to be the best among the semi-bounded distributions (<a href="#fig-semibounded" class="quarto-xref">Figure&nbsp;9</a>). Furthermore, the flexibility of the bounded J-QPD-B is at least as good as that of the Beta and Kumaraswamy distributions (<a href="#fig-bounded" class="quarto-xref">Figure&nbsp;10</a>).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-unbounded" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-unbounded-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/unbounded_final.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-unbounded-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Robust skewness vs robust kurtosis for some unbounded distributions
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-semibounded" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-semibounded-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/semibounded_final.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-semibounded-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Robust skewness vs robust kurtosis for some left-bounded distributions
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bounded" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bounded-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/bounded_final.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bounded-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Robust skewness vs robust kurtosis for some bounded distributions
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-multivariateqpd" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Multivariate quantile-parameterized distributions</h1>
<p>Quantile-parameterized distributions can serve as marginal distributions in multivariate models, where the dependency structure is captured by a standard (parametric) multivariate distribution, a copula, or described by bivariate quantiles. However, the marginal distributions alone are insufficient to determine the corresponding bivariate distribution, resulting in an infinite number of bivariate distributions with the same margins <span class="citation" data-cites="gumbel1960BivariateExponentialDistributions gumbel1961BivariateLogisticDistributions">(<a href="#ref-gumbel1960BivariateExponentialDistributions" role="doc-biblioref">Gumbel, 1960</a>, <a href="#ref-gumbel1961BivariateLogisticDistributions" role="doc-biblioref">1961</a>)</span>. In this section, we describe several methods for extending the distributions parameterized by the quantile-probability pairs to become Multivariate Quantile-Parameterized Distributions (MQPDs).</p>
<section id="mqpds-based-on-standard-multivariate-distributions" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="mqpds-based-on-standard-multivariate-distributions"><span class="header-section-number">4.1</span> MQPDs based on standard multivariate distributions</h2>
<section id="normal-distribution" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="normal-distribution"><span class="header-section-number">4.1.1</span> Normal distribution</h3>
<p>In the simplest case, multivariate Quantile-Parameterized Distributions (MQPDs) can be created by using the multivariate normal distribution, following the approach of <span class="citation" data-cites="hoff2007ExtendingRankLikelihood">(<a href="#ref-hoff2007ExtendingRankLikelihood" role="doc-biblioref">Hoff, 2007</a>)</span>. The Myerson, J-QPD, and SQN quantile functions are Q-transformations of the probit <span class="math inline">\(Q(z(u)\vert\theta)\)</span>, where <span class="math inline">\(z(u)=\Phi^{-1}(u)\)</span> represents the standard normal quantile function. The multivariate versions of these distributions can be viewed as the Q-transformations of the multivariate normal distribution. To extend these QPDs to <span class="math inline">\(J\)</span> dimensions using the multivariate normal distribution, we employ the method outlined in <span class="citation" data-cites="drovandi2011LikelihoodfreeBayesianEstimation">(<a href="#ref-drovandi2011LikelihoodfreeBayesianEstimation" role="doc-biblioref">Drovandi and Pettitt, 2011</a>)</span>.</p>
<p>The <span class="math inline">\(i\)</span>-th component of a single observation <span class="math inline">\(y_i\)</span> can be described by the quantile function:</p>
<p><span class="math display">\[
y_i=Q(z(u_i)\vert\theta_i), \; \text{for }i=1,\dots,J
\]</span></p>
<p>where <span class="math inline">\(\theta_i\)</span> represents the set of parameters for component <span class="math inline">\(i\)</span> (e.g., <span class="math inline">\(\{q_1,q_2,q_3, \alpha\}_i)\)</span> for Myerson or J-QPD distributions). The vector <span class="math inline">\((z(u_1),\dots,z(u_j))^T\sim N(0,\Sigma)\)</span>, where <span class="math inline">\(\Sigma\)</span> denotes the covariance matrix.</p>
<p>For invertible distributions, the inverse quantile function is the cumulative distribution function (CDF) <span class="math inline">\(Q^{-1}(y_i\vert\theta)=F(y_i\vert\theta)\)</span>, otherwise, the inverse can be computed numerically as <span class="math inline">\(\widehat{F}(y_i\vert\theta)=\widehat{Q^{-1}}(y_i\vert\theta)\)</span> <span class="citation" data-cites="perepolkin2023TenetsQuantilebasedInference">(<a href="#ref-perepolkin2023TenetsQuantilebasedInference" role="doc-biblioref">Perepolkin et al., 2023</a>)</span>.</p>
<p>Drovandi and Pettitt <span class="citation" data-cites="drovandi2011LikelihoodfreeBayesianEstimation">(<a href="#ref-drovandi2011LikelihoodfreeBayesianEstimation" role="doc-biblioref">Drovandi and Pettitt, 2011</a>)</span> show that the joint density of a single (multivariate) observation <span class="math inline">\((y_i,\dots,y_J)\)</span> can be expressed as:</p>
<p><span class="math display">\[
f(y_1,\dots,y_J\vert\theta)=\varphi(z(Q^{-1}(y_1\vert\theta_1)),\dots,z(Q^{-1}(y_J\vert\theta_J));\Sigma)\prod_{i=1}^{J}\frac{dQ^{-1}(y_i\vert\theta_i)}{dy_i}
\]</span></p>
<p>where <span class="math inline">\(z(Q^{-1}(y_i\vert\theta_i))=z_i\)</span>, <span class="math inline">\(\varphi(z_1,\dots,z_J;\Sigma)\)</span> represents the multivariate normal density with a mean of zero and a covariance matrix of <span class="math inline">\(\Sigma\)</span>, and <span class="math inline">\(\frac{dQ^{-1}(y_i)}{dy_i}=f(y_i)\)</span> is the probability density function (PDF) of the QPD (refer to Appendix A).</p>
<p>For distributions without a PDF, the same joint density can be expressed as a joint density quantile function</p>
<p><span class="math display">\[
[q(u_1,\dots,u_j)]^{-1}=\varphi(z(u_1),\dots,z(u_J);\Sigma)\prod_{i=1}^{J}[q(u_i\vert\theta_i)]^{-1}
\]</span></p>
<p>since <span class="math inline">\(Q^{-1}(y_i\vert\theta_i)=u_i\)</span> and <span class="math inline">\(f(y_i\vert\theta_i)=[q(u_i\vert\theta_i)]^{-1}\)</span> <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>)</span>.</p>
<p>Itâs worth noting that this method of creating multivariate distributions does not require every component to follow the same distributional form. As illustrated earlier, it is entirely possible to combine several different QPDs using the multivariate Gaussian distribution <span class="citation" data-cites="drovandi2011LikelihoodfreeBayesianEstimation">(<a href="#ref-drovandi2011LikelihoodfreeBayesianEstimation" role="doc-biblioref">Drovandi and Pettitt, 2011</a>)</span>.</p>
<p>To use the MQPD for the prior, both the density of the multivariate normal and the marginal densities need to be explicitly added to the log-likelihood. This is possible when the marginal QPDs used to define the multivariate prior are invertible, such as Myerson and J-QPD, as both the CDF (<span class="math inline">\(Q^{-1}(y_i\vert\theta_i)\)</span>) and PDF (<span class="math inline">\(dQ^{-1}(y_i\vert\theta_i)/dy_i\)</span>) are required.</p>
<p>When a quantile-based prior specification is used, only the multivariate normal log-density needs to be added because the Jacobian for the marginal QF transformation is reciprocal to the DQF of the prior <span class="citation" data-cites="perepolkin2023TenetsQuantilebasedInference">(<a href="#ref-perepolkin2023TenetsQuantilebasedInference" role="doc-biblioref">Perepolkin et al., 2023</a>)</span>.</p>
</section>
<section id="logistic-distribution" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="logistic-distribution"><span class="header-section-number">4.1.2</span> Logistic distribution</h3>
<p>The same approach of joining the marginal QPDs can be applied by using the base quantile functions of other distributions. For instance, the Logit-Myerson distribution <span class="citation" data-cites="wilson2023ReconciliationExpertPriors">(<a href="#ref-wilson2023ReconciliationExpertPriors" role="doc-biblioref">Wilson et al., 2023</a>)</span> is based on the logistic quantile function. Two Logit-Myerson distributions can be connected using the bivariate logistic distribution. <span class="citation" data-cites="gumbel1961BivariateLogisticDistributions">(<a href="#ref-gumbel1961BivariateLogisticDistributions" role="doc-biblioref">Gumbel, 1961</a>)</span> proposed three different formulations for the bivariate logistic distribution. The Type II distribution from the Morgenstern Family <span class="citation" data-cites="sajeevkumar2014EstimationParameterMorgenstern basikhasteh2021BayesianEstimationMorgenstern">(<a href="#ref-sajeevkumar2014EstimationParameterMorgenstern" role="doc-biblioref">Sajeevkumar and Irshad, 2014</a>; <a href="#ref-basikhasteh2021BayesianEstimationMorgenstern" role="doc-biblioref">Basikhasteh et al., 2021</a>)</span> has the following joint distribution and density functions:</p>
<p><span class="math display">\[
\begin{aligned}
F(y_1,y_2\vert\beta)=&amp;F_1(y_1)F_2(y_2)[1+\beta(1-F_1(y_1))(1-F_2(y_2))]\\
f(y_1,y_2\vert\beta)=&amp;f_1(y_1)f_2(y_2)[1+\beta(1-2F_1(y_1))(1-2F_2(y_2))]
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(F_i(y_i)\)</span> and <span class="math inline">\(f_i(y_i)\)</span> for <span class="math inline">\(i\in\{1,2\}\)</span> refer to the univariate logistic distribution and density funcitons, respectively and <span class="math inline">\(-1\leq\beta\leq1\)</span>. Since <span class="math inline">\(y_i=Q_i(u_i)\)</span> we can express the bivariate density in the quantile form</p>
<p><span class="math display">\[
\begin{aligned}
f(Q(u_1),Q(u_2)\vert\beta)=&amp;f_1(Q(u_1))f_2(Q(u_2))[1+\beta(1-2F_1(Q_1(u_1)))(1-2F_2(Q_2(u_2)))]\\
\left[q(u_1,u_2\vert\beta)\right]^{-1}=&amp;[q_1(u_1)]^{-1}[q_2(u_2)]^{-1}\left[1+\beta (1-2u_1)(1-2u_2)\right]
\end{aligned}
\]</span></p>
<p>For logistic distribution <span class="math inline">\(Q(u)=\ln(u)-\ln(1-u)\)</span> and <span class="math inline">\([q(u)]^{-1}=u(1-u)\)</span>. Therefore, the bivariate logistic density quantile function can be expressed as</p>
<p><span class="math display">\[
\left[q_L(u_1,u_2\vert\beta)\right]^{-1}=u_1(1-u_1)u_2(1-u_2)\left[1+\beta (1-2u_1)(1-2u_2)\right]
\]</span></p>
<p>If we combine the QPD marginals, the result is the joint quantile-based density for the bivariate logistic-based QPD, where the dependency is captured by the bivariate logistic distribution with the coupling parameter <span class="math inline">\(\beta\)</span>, and the margins are QPDs. The joint density quantile function is given by:</p>
<p><span class="math display">\[
\begin{aligned}
\left[q_{MQPD}(u_1,u_2\vert\theta_1,\theta_2, \beta)\right]^{-1}=&amp;u_1(1-u_1)u_2(1-u_2)\left[1+\beta (1-2u_1)(1-2u_2)\right]\times\\
&amp;[q_1(u_1\vert\theta_1)]^{-1}[q_2(u_2\vert\theta_2)]^{-1}
\end{aligned}
\]</span></p>
<p>Here, <span class="math inline">\([q_i(u_i\vert\theta_i)]^{-1}\)</span>, for <span class="math inline">\(i=1,2\)</span>, represents the marginal QPD density quantile functions, such as the density quantile function (DQF) of the Logit-Myerson distribution (see Appendix A).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bi-logitmyerson" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bi-logitmyerson-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="qpppp_files/figure-html/fig-bi-logitmyerson-1.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bi-logitmyerson-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Density of Generalized Myerson distributions joined by Type II bivariate logistic distribution
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-bi-logitmyerson" class="quarto-xref">Figure&nbsp;11</a> presents the Bivariate Logit-Myerson Distribution, parameterized by <span class="math inline">\(\Theta=\{\theta_1, \theta_2, \rho\}\)</span>, where the marginal Myerson distributions are given by <span class="math inline">\(y_{ij}=Q_j(z(u_{ij}),\theta_j)\)</span> for <span class="math inline">\(j=1,2\)</span>, with parameter vectors <span class="math inline">\(\theta_1=\{3,7,10;0.25\}\)</span>, <span class="math inline">\(\theta_2=\{1,10,20;0.1\}\)</span>, and the dependence parameter <span class="math inline">\(\beta=0.6\)</span>.</p>
</section>
</section>
<section id="copula-based-mqpds" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="copula-based-mqpds"><span class="header-section-number">4.2</span> Copula-based MQPDs</h2>
<p>The approach we have used so far is similar to constructing the joint distribution using the Gaussian copula <span class="citation" data-cites="hoff2007ExtendingRankLikelihood">(<a href="#ref-hoff2007ExtendingRankLikelihood" role="doc-biblioref">Hoff, 2007</a>)</span>. Copulas provide a general approach to modeling joint distributions, separating the bivariate dependence from the effects of marginal distributions <span class="citation" data-cites="kurowicka2006UncertaintyAnalysisHigh">(<a href="#ref-kurowicka2006UncertaintyAnalysisHigh" role="doc-biblioref">Kurowicka and Cooke, 2006</a>)</span>. The literature describes a wide range of copulas <span class="citation" data-cites="genest2007EverythingYouAlways smith2013BayesianApproachesCopula kurowicka2011DependenceModelingVine">(<a href="#ref-genest2007EverythingYouAlways" role="doc-biblioref">Genest and Favre, 2007</a>; <a href="#ref-smith2013BayesianApproachesCopula" role="doc-biblioref">Smith, 2013</a>; <a href="#ref-kurowicka2011DependenceModelingVine" role="doc-biblioref">Kurowicka and Joe, 2011</a>)</span>, and new copulas can be created using generator functions <span class="citation" data-cites="durrleman2000SimpleTransformationCopulas">(<a href="#ref-durrleman2000SimpleTransformationCopulas" role="doc-biblioref">Durrleman et al., 2000</a>)</span>. When a copula is used to connect QPDs, the joint density is calculated as follows:</p>
<p><span class="math display">\[
f_{MQPD}(y_1,y_2\vert \theta_1,\theta_2,\Xi)=c(F(y_1\vert\theta_1),F(y_2\vert\theta_2)\vert\Xi)
f_1\left(y_1\vert\theta_1\right) f_2\left(y_2\vert\theta_2\right)
\]</span></p>
<p>where <span class="math inline">\(c\)</span> represents the copula density function with parameter <span class="math inline">\(\Xi\)</span>, and <span class="math inline">\(F(y_i\vert\theta_i)\)</span> and <span class="math inline">\(f_i(y_i\vert\theta_i)\)</span> are the CDF and PDF of the marginal quantile-parameterized distributions, respectively.</p>
<p>The same density can be expressed in quantile-based form <span class="citation" data-cites="perepolkin2023TenetsQuantilebasedInference">(<a href="#ref-perepolkin2023TenetsQuantilebasedInference" role="doc-biblioref">Perepolkin et al., 2023</a>)</span>:</p>
<p><span class="math display">\[
[q_{MQPD}(u_1,u_2\vert\theta, \Xi)]^{-1}=c\left(u_1,u_2\vert\Xi\right)[q_1(u_1\vert\theta_1)]^{-1}[q_2(u_2\vert\theta)]^{-1}
\]</span></p>
<p>where <span class="math inline">\(c\)</span> is the copula density function with parameter <span class="math inline">\(\Xi\)</span>, and <span class="math inline">\([q_i(u_i\vert\theta_i)]^{-1}\)</span>, for <span class="math inline">\(i=1,2\)</span>, are the marginal DQFs of QPDs. <a href="#fig-bc-myerson" class="quarto-xref">Figure&nbsp;12</a> presents 10,000 samples from the bivariate Myerson distribution joined by the Joe copula with <span class="math inline">\(\theta=3\)</span>.</p>
<p>Elicitation of multivariate distributions may require a specialized approach <span class="citation" data-cites="elfadaly2017ElicitingDirichletGaussian wilson2021RecentAdvancesElicitation">(<a href="#ref-elfadaly2017ElicitingDirichletGaussian" role="doc-biblioref">Elfadaly and Garthwaite, 2017</a>; <a href="#ref-wilson2021RecentAdvancesElicitation" role="doc-biblioref">Wilson et al., 2021</a>)</span>. For examples of expert-specified multivariate distributions encoded with copulas, we refer to <span class="citation" data-cites="wilson2018SpecificationInformativePrior holzhauer2022ElicitingJudgementsDependent sharma2018RegularizationVariableSelection aas2009PaircopulaConstructionsMultiple">(<a href="#ref-wilson2018SpecificationInformativePrior" role="doc-biblioref">Wilson, 2018</a>; <a href="#ref-holzhauer2022ElicitingJudgementsDependent" role="doc-biblioref">Holzhauer et al., 2022</a>; <a href="#ref-sharma2018RegularizationVariableSelection" role="doc-biblioref">Sharma and Das, 2018</a>; <a href="#ref-aas2009PaircopulaConstructionsMultiple" role="doc-biblioref">Aas et al., 2009</a>)</span>. When fitting copulas to empirical observations, the âblanketâ goodness of fit measure <span class="citation" data-cites="wang2000ModelSelectionSemiparametric">(<a href="#ref-wang2000ModelSelectionSemiparametric" role="doc-biblioref">Wang and Wells, 2000</a>)</span> based on Kendallâs transform <span class="citation" data-cites="genest2006GoodnessofFitProceduresCopula genest2009GoodnessoffitTestsCopulas">(<a href="#ref-genest2006GoodnessofFitProceduresCopula" role="doc-biblioref">Genest et al., 2006</a>; <a href="#ref-genest2009GoodnessoffitTestsCopulas" role="doc-biblioref">Genest et al., 2009</a>)</span> can be used.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bc-myerson" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bc-myerson-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="qpppp_files/figure-html/fig-bc-myerson-1.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bc-myerson-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: Samples from the bivariate Myerson distribution joined by the Joe copula (<span class="math inline">\(\theta=3\)</span>)
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="bivariate-quantiles" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="bivariate-quantiles"><span class="header-section-number">4.3</span> Bivariate quantiles</h2>
<p>The formal definition of bivariate quantile functions and the method for constructing bivariate quantile distributions using marginal and conditional quantile functions are provided by <span class="citation" data-cites="nair2023PropertiesBivariateDistributions vineshkumar2019BivariateQuantileFunctions">(<a href="#ref-nair2023PropertiesBivariateDistributions" role="doc-biblioref">Nair and Vineshkumar, 2023</a>; <a href="#ref-vineshkumar2019BivariateQuantileFunctions" role="doc-biblioref">Vineshkumar and Nair, 2019</a>)</span>. They define the bivarate quantile function (bQF) of <span class="math inline">\((X_1, X_2)\)</span> as the pair <span class="math inline">\(Q(u_1, u_2)=(Q_1(u_1), Q_{21}(u_2\vert u_1))\)</span>, where <span class="math inline">\(Q_1(u_1)=\inf \{x_1: F_1(x_1)\geq u_1\}\)</span>, <span class="math inline">\(u_1\in[0,1]\)</span> and <span class="math inline">\(Q_{21}(u_2\vert u_1)=\inf\{x_2: F_{21}(Q_1, x_2)\geq u_2\}\)</span>.</p>
<p>The conditional quantile function <span class="math inline">\(Q_{21}(u_2\vert u_1)\)</span> can be obtained by inverting the conditional distribution function <span class="math inline">\(F_{21}(x_1, x_2)\)</span>, which is computed from the factorization of the joint survival function. The joint survival function is defined as <span class="math inline">\(\bar{F}(x_1, x_2)=P(X_1&gt; x_1)P(X_2&gt; x_2 \vert X_1 &gt; x_1)= \bar{F}(x_1)\bar{F}_{21}(x_1,x_2)\)</span>. Note that the joint survival function <span class="math inline">\(\bar{F}(x_1,x_2)=1-F_1(x_1)-F_2(x_2)+F(x_1,x_2)\)</span>, and the conditional survival function <span class="math inline">\(\bar{F}_{21}(x_1,x_2)=1-F_{21}(x_1,x_2)\)</span>.</p>
<p>Another approach for creating bivariate quantile functions is through Gilchristâs QF transformation rules <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>)</span>, which can be generalized to bivariate quantile functions. According to <span class="citation" data-cites="nair2023PropertiesBivariateDistributions">(<a href="#ref-nair2023PropertiesBivariateDistributions" role="doc-biblioref">Nair and Vineshkumar, 2023</a>)</span> (Property 6), the conditional QF can be constructed as a sum of two univariate QFs: <span class="math inline">\(Q_{21}(u_2\vert u_1) = Q_1(u_1) + Q_2(u_2)\)</span>. This means that the pair <span class="math inline">\((Q_1(u_1), ; Q_1(u_1) + Q_2(u_2))\)</span> is a valid bivariate quantile function, which generalizes Gilchristâs <em>addition rule</em> (<a href="#tbl-qf-trans" class="quarto-xref">Table&nbsp;1</a>). The addition rule also works for quantile density functions (Property 7). If <span class="math inline">\(Q_1\)</span> is left-bounded at zero, i.e., <span class="math inline">\(Q_1(0) = 0\)</span>, then the margins of such a bQF are <span class="math inline">\(X_1 = Q_1(u_1)\)</span> and <span class="math inline">\(X_2 = Q_2(u_2)\)</span>. Otherwise, the marginal distribution of <span class="math inline">\(X_2\)</span> will be <span class="math inline">\(\lim_{u_1 \rightarrow 0}Q_{21}(u_2\vert u_1)\)</span>, which in many cases is not tractable.</p>
<p>If <span class="math inline">\(Q_1(u_1)\)</span> and <span class="math inline">\(Q_2(u_2)\)</span> are positive on <span class="math inline">\(u_i \in [0,1]\)</span>, then their product is also a valid conditional QF (Property 8), generalizing Gilchristâs âproduct ruleâ. Finally, Property 9 generalizes the âQ-transformation rule,â stating that for every increasing transformation functions <span class="math inline">\(T_1\)</span> and <span class="math inline">\(T_2\)</span>, <span class="math inline">\(\left(T_1(Q_1(u_1)), T_1(Q_1(u_1)) + T_2(Q_2(u_2))\right)\)</span> is also a valid bQF.</p>
<p>Therefore, valid bivariate quantile-parameterized QFs can be created by constructing the conditional quantile functions as Gilchrist combinations of univariate quantile-parameterized QFs. <a href="#fig-bq-myerson" class="quarto-xref">Figure&nbsp;13</a> shows 1000 samples from the bivariate distribution created by adding together two Myerson distributions. Note that in this case, only the marginal distribution of <span class="math inline">\(x_1 = Q_1(u_1)\)</span> is available in closed form.</p>
<p><span class="math display">\[
\begin{aligned}
(u_1, u_2) &amp;\overset{X_1, X_2}{\backsim} (Q_1(u_1), Q_1(u_1)+Q_2(u_2))\\
Q_1(u_1) &amp;\sim\text{Myerson}(3,7,10; 0.1)\\
Q_2(u_2) &amp;\sim \text{Myerson}(-9, -3, 2; 0.25)\\
\end{aligned}
\]</span></p>
<p>This bQF is easy to elicit and interpret, since <span class="math inline">\(Q_2(u_2)\)</span> can be thought of as a random adjustment to the value of <span class="math inline">\(Q_1(u_1)\)</span>. In fact, the conditional quantile function <span class="math inline">\(Q_{21}(u_2\vert u_1)\)</span> can be thought of as having the classical form <span class="math inline">\(Q_{21}(u_2\vert u_1) = \mu(u_1) + \sigma Q_2(u_2)\)</span> <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>)</span>, where the location is randomly varying with <span class="math inline">\(\mu(u_1) = Q_1(u_1)\)</span> and the scale parameter <span class="math inline">\(\sigma = 1\)</span>. First, the marginal distribution <span class="math inline">\(Q_1(u_1)\)</span> is elicited, and then the difference between the values <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> can be elicited as a QPT and encoded as <span class="math inline">\(Q_2(u_2)\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bq-myerson" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bq-myerson-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="qpppp_files/figure-html/fig-bq-myerson-1.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bq-myerson-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: Samples from the Bivariate Myerson quantile function
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="discussion" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Discussion</h1>
<p>Quantile-based distributions have garnered significant attention in the research community. Several distributions, such as the Generalized Lambda Distribution (GLD) <span class="citation" data-cites="freimer1988StudyGeneralizedTukey ramberg1974ApproximateMethodGenerating">(<a href="#ref-freimer1988StudyGeneralizedTukey" role="doc-biblioref">Freimer et al., 1988</a>; <a href="#ref-ramberg1974ApproximateMethodGenerating" role="doc-biblioref">Ramberg and Schmeiser, 1974</a>)</span>, the g-and-k distribution <span class="citation" data-cites="haynes1997RobustnessRankingSelection haynes2005BayesianEstimationGandk jacob2017LikelihoodCalculationGandk prangle2017GkPackageGandk">(<a href="#ref-haynes1997RobustnessRankingSelection" role="doc-biblioref">Haynes et al., 1997</a>; <a href="#ref-haynes2005BayesianEstimationGandk" role="doc-biblioref">Haynes and Mengersen, 2005</a>; <a href="#ref-jacob2017LikelihoodCalculationGandk" role="doc-biblioref">Jacob, 2017</a>; <a href="#ref-prangle2017GkPackageGandk" role="doc-biblioref">Prangle, 2017</a>)</span>, the g-and-h distribution <span class="citation" data-cites="field2006MultivariateGandhDistribution macgillivray1992ShapePropertiesGandh rayner2002NumericalMaximumLikelihood">(<a href="#ref-field2006MultivariateGandhDistribution" role="doc-biblioref">Field and Genton, 2006</a>; <a href="#ref-macgillivray1992ShapePropertiesGandh" role="doc-biblioref">Mac Gillivray, 1992</a>; <a href="#ref-rayner2002NumericalMaximumLikelihood" role="doc-biblioref">Rayner and MacGillivray, 2002</a>)</span>, and the Wakeby distribution <span class="citation" data-cites="jeong-soo2005WakebyDistributionMaximum rahman2015ApplicabilityWakebyDistribution tarsitano2005FittingWakebyModel">(<a href="#ref-jeong-soo2005WakebyDistributionMaximum" role="doc-biblioref">Jeong-Soo, 2005</a>; <a href="#ref-rahman2015ApplicabilityWakebyDistribution" role="doc-biblioref">Rahman et al., 2015</a>; <a href="#ref-tarsitano2005FittingWakebyModel" role="doc-biblioref">Tarsitano, 2005a</a>)</span>, have been extensively studied and documented in the literature. These distributions are defined by non-invertible quantile functions <span class="citation" data-cites="perepolkin2023TenetsQuantilebasedInference">(<a href="#ref-perepolkin2023TenetsQuantilebasedInference" role="doc-biblioref">Perepolkin et al., 2023</a>)</span>. However, the research on quantile-parameterized distributions remains relatively unexplored. These distributions offer interpretable parameters that are defined on the same scale as the quantities of interest, simplifying the elicitation process for experts. Many popular elicitation protocols for both predictive and parametric elicitation rely on the assessment of quantile-probability pairs (QPPs). Instead of fitting a parametric distribution to the elicited QPPs <span class="citation" data-cites="best2020PriorElicitation ohagan2019ExpertKnowledgeElicitation">(<a href="#ref-best2020PriorElicitation" role="doc-biblioref">Best et al., 2020</a>; <a href="#ref-ohagan2019ExpertKnowledgeElicitation" role="doc-biblioref">OâHagan, 2019</a>)</span>, assessors could directly use the elicited QPPs as inputs into one of the QPD quantile functions, which can be easily employed in both quantile-parameterized and parametric models.</p>
<p>Provided that the expert and the elicitor agree on the scientific model to be used for representing the expertâs understanding of the world <span class="citation" data-cites="burgman2021ElicitingModelStructures">(<a href="#ref-burgman2021ElicitingModelStructures" role="doc-biblioref">Burgman et al., 2021</a>)</span>, several types of inputs may be required to inform the model. Among those are the expertâs judgement about the model <em>parameters</em> <span class="citation" data-cites="mikkola2021PriorKnowledgeElicitation ohagan2019ExpertKnowledgeElicitation">(<a href="#ref-mikkola2021PriorKnowledgeElicitation" role="doc-biblioref">Mikkola et al., 2021</a>; <a href="#ref-ohagan2019ExpertKnowledgeElicitation" role="doc-biblioref">OâHagan, 2019</a>)</span> and their <em>predictions</em> of the next observation <span class="citation" data-cites="akbarov2009ProbabilityElicitationPredictive kadane1998ExperiencesElicitation winkler1980PriorInformationPredictive">(<a href="#ref-akbarov2009ProbabilityElicitationPredictive" role="doc-biblioref">Akbarov, 2009</a>; <a href="#ref-kadane1998ExperiencesElicitation" role="doc-biblioref">Kadane and Wolfson, 1998</a>; <a href="#ref-winkler1980PriorInformationPredictive" role="doc-biblioref">Winkler, 1980</a>)</span>. Both parametric and predictive judgments should be captured together with corresponding uncertainties to reflect the expertâs state of knowledge. Quantile-parameterized distributions offer distinct advantages as high-fidelity priors that precisely capture expert assessments. These distributions are particularly beneficial for domain experts who may not be well-versed in statistics, as they provide high flexibility while retaining parameter interpretability. As a result, QPDs can faithfully represent an expertâs beliefs without compromising convenience or precision.</p>
<p>Different quantile-parameterized distributions fitted to the same set of quantile-probability pairs may exhibit slight variations in shape. However, given the diverse range of QPDs proposed in the literature a knowledgeable assessor should be able to select an appropriate distribution and validate the choice with the expert, taking into account the thickness of the distribution tails.</p>
<p>Most QPDs we reviewed are parameterized by a symmetric percentile triplet (SPT). These distributions rely on the symmetric property of underlying <em>kernel</em> distributions and can be generalized by swapping the distribution with another one that exhibits different tail shapes. Hadlock and Bickel <span class="citation" data-cites="hadlock2019GeneralizedJohnsonQuantileParameterized">(<a href="#ref-hadlock2019GeneralizedJohnsonQuantileParameterized" role="doc-biblioref">Hadlock and Bickel, 2019</a>)</span> utilized this method to generalize Johnson Quantile Parameterized distributions (J-QPDs). We show that the variants of Myerson distribution appearing in the literature <span class="citation" data-cites="myerson2005ProbabilityModelsEconomic wilson2023ReconciliationExpertPriors">(<a href="#ref-myerson2005ProbabilityModelsEconomic" role="doc-biblioref">Myerson, 2005</a>; <a href="#ref-wilson2023ReconciliationExpertPriors" role="doc-biblioref">Wilson et al., 2023</a>)</span> represent similar generalization. This principle can be extended to include other kernels which result in varying thickness of the tails.</p>
<section id="quantile-function-perspective" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="quantile-function-perspective">Quantile function perspective</h3>
<p>The distributions discussed in this paper are defined using the quantile function and, therefore, they can be considered <em>quantile-based</em> quantile-parameterized distributions. Myerson, J-QPD, and several other quantile-parameterized distributions reparameterize conventional distributions, utilizing Gilchristâs Quantile Function (QF) transformations <span class="citation" data-cites="gilchrist2000StatisticalModellingQuantile">(<a href="#ref-gilchrist2000StatisticalModellingQuantile" role="doc-biblioref">Gilchrist, 2000</a>)</span>.</p>
<p>Perepolkin et al. <span class="citation" data-cites="perepolkin2023TenetsQuantilebasedInference">(<a href="#ref-perepolkin2023TenetsQuantilebasedInference" role="doc-biblioref">Perepolkin et al., 2023</a>)</span> demonstrated that the distributions defined by the quantile function can be used both as prior and as likelihood in Bayesian models. Priors defined by the quantile function eliminate the need to compute prior density. The quantile function acts as a non-linear transformation of a uniform degenerate random variate with the resulting Jacobian adjustment reciprocal to the density quantile function. Therefore, both the Jacobian and the density quantile function are omitted from the Bayesian updating equation <span class="citation" data-cites="perepolkin2023TenetsQuantilebasedInference">(<a href="#ref-perepolkin2023TenetsQuantilebasedInference" role="doc-biblioref">Perepolkin et al., 2023</a>)</span>. When using quantile-based QPDs as likelihood, special care needs to be taken with regards to the suitable prior for the QPP parameters. <span class="citation" data-cites="perepolkin2021HybridElicitationIndirect">(<a href="#ref-perepolkin2021HybridElicitationIndirect" role="doc-biblioref">Perepolkin et al., 2021</a>)</span> used the Dirichet-based prior for the metalog likelihood model and descibed the <em>hybrid</em> elicitation process for encoding the expert judgments into the two-dimensional prior distribution implied by the model.</p>
</section>
<section id="feasibility-of-parameters" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="feasibility-of-parameters">Feasibility of parameters</h3>
<p>Not all QPDs are equally reliable in approximating the underlying distributions. Violating the QF transformation rules imposes additional constraints on the feasibility of parameters, as certain combinations of parameters may result in locally decreasing quantile functions <span class="citation" data-cites="keelin2016MetalogDistributions hadlock2017QuantileparameterizedMethodsQuantifying">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>; <a href="#ref-hadlock2017QuantileparameterizedMethodsQuantifying" role="doc-biblioref">Hadlock, 2017</a>)</span>. We discussed this limitation in relation to SQN and metalog distributions, but the same challenges affect other distributions with QF violating Gilchrist QF transformation rules. In this regard, the quantile-parameterized model, which relies on Gilchrist combination of basic quantile functions, proposed by <span class="citation" data-cites="peng2023MixtureQuantilesEstimated">(<a href="#ref-peng2023MixtureQuantilesEstimated" role="doc-biblioref">Peng et al., 2023</a>)</span>, represents a highly promising advancement. Weighted constrained optimization algorithm ensuring that the quantile mixture weights remain non-negative opens new possibilities for other QPDs using monotonic transformations of quantile functions. The estimator proposed by <span class="citation" data-cites="peng2023MixtureQuantilesEstimated">(<a href="#ref-peng2023MixtureQuantilesEstimated" role="doc-biblioref">Peng et al., 2023</a>)</span> is asymptotically a q-Wasserstein distance, which has also been used for parameter estimation in Approximate Bayesian Computation <span class="citation" data-cites="bernton2019ParameterEstimationWasserstein">(<a href="#ref-bernton2019ParameterEstimationWasserstein" role="doc-biblioref">Bernton et al., 2019</a>)</span>.</p>
<p>The feasibility conditions for the Generalized Lambda Distribution (GLD) have been a focal point of numerous research endeavors in the past <span class="citation" data-cites="dean2013ImprovedEstimationRegression fournier2007EstimatingParametersGeneralized karian2019FittingStatisticalDistributions king2007FittingGeneralizedLambda tarsitano2005EstimationGeneralizedLambda">(<a href="#ref-dean2013ImprovedEstimationRegression" role="doc-biblioref">Dean, 2013</a>; <a href="#ref-fournier2007EstimatingParametersGeneralized" role="doc-biblioref">Fournier et al., 2007</a>; <a href="#ref-karian2019FittingStatisticalDistributions" role="doc-biblioref">Karian and Dudewicz, 2019</a>; <a href="#ref-king2007FittingGeneralizedLambda" role="doc-biblioref">King and MacGillivray, 2007</a>; <a href="#ref-tarsitano2005EstimationGeneralizedLambda" role="doc-biblioref">Tarsitano, 2005b</a>, etc)</span>. Various reparameterizations have been explored to enhance parameter identifiability <span class="citation" data-cites="ramberg1974ApproximateMethodGenerating">(<a href="#ref-ramberg1974ApproximateMethodGenerating" role="doc-biblioref">Ramberg and Schmeiser, 1974</a>)</span>. Recently, <span class="citation" data-cites="chalabi2012FlexibleDistributionModeling">(<a href="#ref-chalabi2012FlexibleDistributionModeling" role="doc-biblioref">Chalabi et al., 2012</a>)</span> proposed a novel asymmetry-skewness reparameterization for the previously popular Freimer, Kollia, Mudholkar &amp; Lin version of GLD (FKML GLD) <span class="citation" data-cites="freimer1988StudyGeneralizedTukey">(<a href="#ref-freimer1988StudyGeneralizedTukey" role="doc-biblioref">Freimer et al., 1988</a>)</span>, wherein two of the four parameters are mapped to robust quantile-based moments, namely the median and Interquartile Range (IQR). This reduction in the number of parameters required for data fitting simplifies the previously computationally intensive fitting algorithms. As demonstrated in the plot of robust moments (<a href="#fig-unbounded" class="quarto-xref">Figure&nbsp;8</a>) GLD remains one of the most flexible unbounded distributions, capable of accommodating a wide range of shapes. <span class="citation" data-cites="dedduwakumara2021EfficientEstimatorParameters">(<a href="#ref-dedduwakumara2021EfficientEstimatorParameters" role="doc-biblioref">Dedduwakumara et al., 2021</a>)</span> described a two-step method for fitting FKML GLD using the probability density quantile function <span class="citation" data-cites="staudte2017ShapesThingsCome">(<a href="#ref-staudte2017ShapesThingsCome" role="doc-biblioref">Staudte, 2017</a>)</span>. However, when applying their method to fitting the CSW GLD, the second step becomes unnecessary as the location and scale can be directly mapped to the empirical first and second robust moments.</p>
<p>CSW GLD represents a prime example of clever reparameterization aiming at alleviating the deficiencies of QF construction through setting consistent parameter boundaries and defining fall-back cases for an impossible combination of parameters. This degree of reparameterization is difficult for QPDs because the objective is to retain the mapping of parameters to the valid set of quantile-probability pairs. Therefore, for improperly constructed QPDs the feasibility conditions will have to be expressed as ratios of quantiles.</p>
</section>
<section id="multivariate-extensions" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="multivariate-extensions">Multivariate extensions</h3>
<p>Quantile-parameterized distributions can be readily extended to the multivariate setting by leveraging traditional multivariate distributions. The combination of quantile-based marginal distributions joined by the multivariate normal has been previously discussed in the literature <span class="citation" data-cites="drovandi2011LikelihoodfreeBayesianEstimation hoff2007ExtendingRankLikelihood">(<a href="#ref-drovandi2011LikelihoodfreeBayesianEstimation" role="doc-biblioref">Drovandi and Pettitt, 2011</a>; <a href="#ref-hoff2007ExtendingRankLikelihood" role="doc-biblioref">Hoff, 2007</a>)</span>. Building on this approach, we proposed the use of Gumbelâs bivariate logistic distribution <span class="citation" data-cites="gumbel1961BivariateLogisticDistributions">(<a href="#ref-gumbel1961BivariateLogisticDistributions" role="doc-biblioref">Gumbel, 1961</a>)</span> to combine quantile-parameterized Logit-Myerson distributions <span class="citation" data-cites="wilson2023ReconciliationExpertPriors">(<a href="#ref-wilson2023ReconciliationExpertPriors" role="doc-biblioref">Wilson et al., 2023</a>)</span>.</p>
<p>Copulas offer a natural extension of univariate QPDs into the multivariate domain. Bivariate copulas can be assembled into more complex structures using vine copulas <span class="citation" data-cites="czado2019AnalyzingDependentData kurowicka2011DependenceModelingVine wilson2018SpecificationInformativePrior">(<a href="#ref-czado2019AnalyzingDependentData" role="doc-biblioref">Czado, 2019</a>; <a href="#ref-kurowicka2011DependenceModelingVine" role="doc-biblioref">Kurowicka and Joe, 2011</a>; <a href="#ref-wilson2018SpecificationInformativePrior" role="doc-biblioref">Wilson, 2018</a>)</span>. Flexible QPDs serve as a viable alternative to empirical copulas, where the margins are represented by kernel density estimation (KDE) or other non-parametric approaches. Poorly fitted marginal distributions mean <em>less-than-ideal</em> starting point for copula modeling, because of deviations from uniformality of the copula margins.</p>
<p>Quantile-parameterized distributions defined by the quantile function are particularly well-suited for constructing new distributions using bivariate quantiles <span class="citation" data-cites="nair2023PropertiesBivariateDistributions vineshkumar2019BivariateQuantileFunctions">(<a href="#ref-nair2023PropertiesBivariateDistributions" role="doc-biblioref">Nair and Vineshkumar, 2023</a>; <a href="#ref-vineshkumar2019BivariateQuantileFunctions" role="doc-biblioref">Vineshkumar and Nair, 2019</a>)</span>. The ability to construct a conditional quantile function as a Gilchrist combination of univariate quantile functions offers a convenient and interpretable approach to defining bivariate distributions, especially when the univariate quantile functions are parameterized by quantiles. These distributions are easy to sample from and construct. However, fitting these distributions to data or posterior samples can be challenging. As shown by <span class="citation" data-cites="castillo1997FittingContinuousBivariate">(<a href="#ref-castillo1997FittingContinuousBivariate" role="doc-biblioref">Castillo et al., 1997</a>)</span> the fitting process requires all marginal and conditional quantile functions to be available in closed form, which is often unattainable.</p>
</section>
<section id="further-research" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="further-research">Further research</h3>
<p>There appears to be a limited availability of unbounded quantile-parameterized distributions in the current literature. Among the distributions we examined, only the metalog distribution and quantile mixtures can extend across the entire real line. The G-QPD system provides clear distributional bounds explicitly defined by the expert during elicitation. In contrast, the (Generalized) Myerson distribution system relies on implicit bounds that need to be communicated to the expert. Most of the distributions we reviewed are characterized by a symmetrical percentile triplet (SPT), as they rely on the symmetrical property of their kernels. However, there may be situations where an arbitrary (non-symmetrical) quantile parameterization could prove valuable <span class="citation" data-cites="perepolkin2021HybridElicitationIndirect">(as shown by <a href="#ref-perepolkin2021HybridElicitationIndirect" role="doc-biblioref">Perepolkin et al., 2021</a>)</span>. The development of flexible quantile-parameterized distributions defined by an arbitrary set of quantile-probability pairs using quantile mixtures <span class="citation" data-cites="peng2023MixtureQuantilesEstimated">(<a href="#ref-peng2023MixtureQuantilesEstimated" role="doc-biblioref">Peng et al., 2023</a>)</span> can enhance versatility of QPDs and facilitate their broader adoption.</p>
<p>In conclusion, quantile-parameterized distributions offer a valuable framework for capturing expert assessments and incorporating them into statistical models. They provide high flexibility and parameter interpretability, making them particularly beneficial for domain experts. The diverse range of quantile-parameterized distributions explored in the literature allows for customized modeling approaches that align with the expertâs beliefs and uncertainties. By embracing these innovative distributions, researchers and practitioners can enhance the accuracy and reliability of their statistical models while leveraging expert knowledge effectively.</p>
</section>
</section>
<section id="miscellaneous" class="level1 unnumbered">
<h1 class="unnumbered">Miscellaneous</h1>
<section id="acknowledgments" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="acknowledgments">Acknowledgments</h2>
<p>The authors have no conflict of interest to declare. We thank the editorial team and reviewers for their constructive feedback which helped us improve this manuscript.</p>
</section>
<section id="orcid" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="orcid">ORCID</h2>
<p>Dmytro Perepolkin https://orcid.org/0000-0001-8558-6183<br>
Erik LindstrÃ¶m https://orcid.org/0000-0002-6468-2624<br>
Ullrika Sahlin http://orcid.org/0000-0002-2932-6253</p>
</section>
</section>

<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-aas2009PaircopulaConstructionsMultiple" class="csl-entry" role="listitem">
Aas, K., C. Czado, A. Frigessi, and H. Bakken (2009), <span>â<a href="https://doi.org/bmnchh">Pair-copula constructions of multiple dependence</a>,â</span> <em>Insurance: Mathematics and Economics</em>, 44(2), 182â198.
</div>
<div id="ref-akbarov2009ProbabilityElicitationPredictive" class="csl-entry" role="listitem">
Akbarov, A. (2009), Probability elicitation: <span>Predictive</span> approach, PhD thesis, University of Salford.
</div>
<div id="ref-arachchige2022RobustAnalogsCoefficient" class="csl-entry" role="listitem">
Arachchige, C.N.P.G., L.A. Prendergast, and R.G. Staudte (2022), <span>â<a href="https://doi.org/10.1080/02664763.2020.1808599">Robust analogs to the coefficient of variation</a>,â</span> <em>Journal of Applied Statistics</em>, 49(2), 268â290.
</div>
<div id="ref-basikhasteh2021BayesianEstimationMorgenstern" class="csl-entry" role="listitem">
Basikhasteh, M., F. Lak, and S. Tahmasebi (2021), <span>â<a href="https://doi.org/10.15446/rce.v44n2.87825">Bayesian <span>Estimation</span> of <span>Morgenstern Type Bivariate Rayleigh Distribution Using Some Types</span> of <span>Ranked Set Sampling</span></a>,â</span> <em>Revista Colombiana de Estad<span>Ã­</span>stica</em>, 44(2), 279â296.
</div>
<div id="ref-berkson1951WhyPreferLogits" class="csl-entry" role="listitem">
Berkson, J. (1951), <span>â<a href="https://doi.org/10.2307/3001655">Why <span>I Prefer Logits</span> to <span>Probits</span></a>,â</span> <em>Biometrics</em>, 7(4), 327â339.
</div>
<div id="ref-bernton2019ParameterEstimationWasserstein" class="csl-entry" role="listitem">
Bernton, E., P.E. Jacob, M. Gerber, and C.P. Robert (2019), <span>â<a href="https://doi.org/10.1093/imaiai/iaz003">On parameter estimation with the <span>Wasserstein</span> distance</a>,â</span> <em>Information and Inference: A Journal of the IMA</em>, 8(4), 657â676.
</div>
<div id="ref-best2020PriorElicitation" class="csl-entry" role="listitem">
Best, N., N. Dallow, and T. Montague (2020), <span>â<a href="https://doi.org/10.1201/9781315180212-5">Prior elicitation</a>,â</span> <em>Bayesian methods in pharmaceutical research</em>, 87â109.
</div>
<div id="ref-boos1986BootstrapMethodsUsing" class="csl-entry" role="listitem">
Boos, D.D., and J.F. Monahan (1986), <span>â<a href="https://doi.org/10.2307/2336273">Bootstrap <span>Methods Using Prior Information</span></a>,â</span> <em>Biometrika</em>, 73(1), 77â83.
</div>
<div id="ref-bowley1920ElementsStatistics" class="csl-entry" role="listitem">
Bowley, A.L. (1920), <em>Elements of statistics</em>, Scribnerâs, New York, NY.
</div>
<div id="ref-brand2019CumulativeScienceBayesian" class="csl-entry" role="listitem">
Brand, C.O., J.P. Ounsley, D.J. van der Post, and T.J.H. Morgan (2019), <span>â<a href="https://doi.org/10.15626/MP.2017.840">Cumulative <span>Science</span> via <span>Bayesian Posterior Passing</span>: <span>An Introduction</span></a>,â</span> <em>Meta-Psychology</em>, 3.
</div>
<div id="ref-burgman2021ElicitingModelStructures" class="csl-entry" role="listitem">
Burgman, M., H. Layman, and S. French (2021), <span>â<a href="https://doi.org/10.3389/fams.2021.668037">Eliciting <span>Model Structures</span> for <span>Multivariate Probabilistic Risk Analysis</span></a>,â</span> <em>Frontiers in Applied Mathematics and Statistics</em>, 7.
</div>
<div id="ref-castillo1997FittingContinuousBivariate" class="csl-entry" role="listitem">
Castillo, E., J.M. Sarabia, and A.S. Hadi (1997), <span>â<a href="https://doi.org/10.1111/1467-9884.00089">Fitting continuous bivariate distributions to data</a>,â</span> <em>Journal of the Royal Statistical Society: Series D (The Statistician)</em>, 46(3), 355â369.
</div>
<div id="ref-chalabi2012FlexibleDistributionModeling" class="csl-entry" role="listitem">
Chalabi, Y., D.J. Scott, and D. Wuertz (2012), <span>âFlexible distribution modeling with the generalized lambda distribution,â</span> Working Paper No. MPRA Paper No. 43333, ETH, Zurich, Switzerland.
</div>
<div id="ref-cullen1999ProbabilisticTechniquesExposure" class="csl-entry" role="listitem">
Cullen, A.C., H.C. Frey, and C.H. Frey (1999), <em>Probabilistic techniques in exposure assessment: A handbook for dealing with variability and uncertainty in models and inputs</em>, Springer Science &amp; Business Media.
</div>
<div id="ref-czado2019AnalyzingDependentData" class="csl-entry" role="listitem">
Czado, C. (2019), <em>Analyzing dependent data with vine copulas</em>, Springer Berlin Heidelberg, New York, NY.
</div>
<div id="ref-dean2013ImprovedEstimationRegression" class="csl-entry" role="listitem">
Dean, B. (2013), Improved estimation and regression techniques with the generalised lambda distribution, PhD thesis, University of Newcastle, Callaghan, Australia.
</div>
<div id="ref-dedduwakumara2021EfficientEstimatorParameters" class="csl-entry" role="listitem">
Dedduwakumara, D.S., L.A. Prendergast, and R.G. Staudte (2021), <span>â<a href="https://doi.org/10.1080/00949655.2020.1808979">An efficient estimator of the parameters of the generalized lambda distribution</a>,â</span> <em>Journal of Statistical Computation and Simulation</em>, 91(1), 197â215.
</div>
<div id="ref-drovandi2011LikelihoodfreeBayesianEstimation" class="csl-entry" role="listitem">
Drovandi, C.C., and A.N. Pettitt (2011), <span>â<a href="https://doi.org/10.1016/j.csda.2011.03.019">Likelihood-free <span>Bayesian</span> estimation of multivariate quantile distributions</a>,â</span> <em>Computational Statistics &amp; Data Analysis</em>, 55(9), 2541â2556.
</div>
<div id="ref-dunson2005ApproximateBayesianInference" class="csl-entry" role="listitem">
Dunson, D.B., and J.A. Taylor (2005), <span>â<a href="https://doi.org/10.1080/10485250500039049">Approximate <span>Bayesian</span> inference for quantiles</a>,â</span> <em>Journal of Nonparametric Statistics</em>, 17(3), 385â400.
</div>
<div id="ref-durrleman2000SimpleTransformationCopulas" class="csl-entry" role="listitem">
Durrleman, V., A. Nikeghbali, and T. Roncalli (2000), <span>â<a href="https://doi.org/10.2139/ssrn.1032543">A simple transformation of copulas</a>,â</span> <em>Available at SSRN 1032543</em>.
</div>
<div id="ref-efsa2023RiskAssessmentCitripestis" class="csl-entry" role="listitem">
EFSA, P. on P.H., C. Bragard, P. Baptista, E. Chatzivassiliou, F. Di Serio, P. Gonthier, J.A. Jaques Miret, A.F. Justesen, A. MacLeod, C.S. Magnusson, P. Milonas, J.A. Navas-Cortes, S. Parnell, R. Potting, P.L. Reignault, E. Stefani, H.-H. Thulke, W. van der Werf, J. Yuen, L. ZappalÃ , D. Makowski, A. Maiorano, O. Mosbach-Schulz, M. Pautasso, and A. Vicent Civera (2023), <span>â<a href="https://doi.org/10.2903/j.efsa.2023.7838">Risk assessment of <span>Citripestis</span> sagittiferella for the <span>EU</span></a>,â</span> <em>EFSA Journal</em>, 21(2), e07838.
</div>
<div id="ref-elfadaly2017ElicitingDirichletGaussian" class="csl-entry" role="listitem">
Elfadaly, F.G., and P.H. Garthwaite (2017), <span>â<a href="https://doi.org/10.1007/s11222-016-9632-7">Eliciting <span>Dirichlet</span> and <span>Gaussian</span> copula prior distributions for multinomial models</a>,â</span> <em>Statistics and Computing</em>, 27(2), 449â467.
</div>
<div id="ref-field2006MultivariateGandhDistribution" class="csl-entry" role="listitem">
Field, C., and M.G. Genton (2006), <span>â<a href="https://doi.org/10.1198/004017005000000562">The <span>Multivariate</span> g-and-h <span>Distribution</span></a>,â</span> <em>Technometrics</em>, 48(1), 104â111.
</div>
<div id="ref-fiori2009KarlPearsonOrigin" class="csl-entry" role="listitem">
Fiori, A.M., and M. Zenga (2009), <span>â<a href="https://doi.org/10.1111/j.1751-5823.2009.00076.x">Karl <span>Pearson</span> and the origin of kurtosis</a>,â</span> <em>International Statistical Review</em>, 77(1), 40â50.
</div>
<div id="ref-fournier2007EstimatingParametersGeneralized" class="csl-entry" role="listitem">
Fournier, B., N. Rupin, M. Bigerelle, D. Najjar, A. Iost, and R. Wilcox (2007), <span>â<a href="https://doi.org/10.1016/j.csda.2006.09.043">Estimating the parameters of a generalized lambda distribution</a>,â</span> <em>Computational Statistics &amp; Data Analysis</em>, 51(6), 2813â2835.
</div>
<div id="ref-freimer1988StudyGeneralizedTukey" class="csl-entry" role="listitem">
Freimer, M., G. Kollia, G.S. Mudholkar, and C.T. Lin (1988), <span>â<a href="https://doi.org/10.1080/03610928808829820">A study of the generalized <span>Tukey</span> lambda family</a>,â</span> <em>Communications in Statistics-Theory and Methods</em>, 17(10), 3547â3567.
</div>
<div id="ref-gabry2022CmdstanrInterfaceCmdStan" class="csl-entry" role="listitem">
Gabry, J., and R. ÄeÅ¡novar (2022), <em>Cmdstanr: <span>R</span> interface to â<span>CmdStan</span>â</em>, cmdstanr document.
</div>
<div id="ref-genest2007EverythingYouAlways" class="csl-entry" role="listitem">
Genest, C., and A.-C. Favre (2007), <span>â<a href="https://doi.org/10.1061/(asce)1084-0699(2007)12:4(347)">Everything <span>You Always Wanted</span> to <span>Know</span> about <span>Copula Modeling</span> but <span>Were Afraid</span> to <span>Ask</span></a>,â</span> <em>Journal of Hydrologic Engineering</em>, 12(4), 347â368.
</div>
<div id="ref-genest2006GoodnessofFitProceduresCopula" class="csl-entry" role="listitem">
Genest, C., J.-F. Quessy, and B. RÃ©millard (2006), <span>â<a href="https://doi.org/10.1111/j.1467-9469.2006.00470.x">Goodness-of-<span>Fit Procedures</span> for <span>Copula Models Based</span> on the <span>Probability Integral Transformation</span></a>,â</span> <em>Scandinavian Journal of Statistics</em>, 33(2), 337â366.
</div>
<div id="ref-genest2009GoodnessoffitTestsCopulas" class="csl-entry" role="listitem">
Genest, C., B. RÃ©millard, and D. Beaudoin (2009), <span>â<a href="https://doi.org/10.1016/j.insmatheco.2007.10.005">Goodness-of-fit tests for copulas: <span>A</span> review and a power study</a>,â</span> <em>Insurance: Mathematics and Economics</em>, 44(2), 199â213.
</div>
<div id="ref-gilchrist2000StatisticalModellingQuantile" class="csl-entry" role="listitem">
Gilchrist, W. (2000), <em>Statistical modelling with quantile functions</em>, Chapman &amp; Hall/CRC, Boca Raton.
</div>
<div id="ref-gosling2018SHELFSheffieldElicitation" class="csl-entry" role="listitem">
Gosling, J.P. (2018), <span>â<span>SHELF</span>: The <span>Sheffield</span> elicitation framework,â</span> in: <em>Elicitation</em>, Springer, pp. 61â93.
</div>
<div id="ref-groeneveld1998ClassQuantileMeasures" class="csl-entry" role="listitem">
Groeneveld, R.A. (1998), <span>â<a href="https://doi.org/10.1080/00031305.1998.10480590">A <span>Class</span> of <span>Quantile Measures</span> for <span>Kurtosis</span></a>,â</span> <em>The American Statistician</em>, 52(4), 325â329.
</div>
<div id="ref-gumbel1960BivariateExponentialDistributions" class="csl-entry" role="listitem">
Gumbel, E.J. (1960), <span>â<a href="https://doi.org/10.2307/2281591">Bivariate <span>Exponential Distributions</span></a>,â</span> <em>Journal of the American Statistical Association</em>, 55(292), 698â707.
</div>
<div id="ref-gumbel1961BivariateLogisticDistributions" class="csl-entry" role="listitem">
ââ (1961), <span>â<a href="https://doi.org/10.2307/2282259">Bivariate <span>Logistic Distributions</span></a>,â</span> <em>Journal of the American Statistical Association</em>, 56(294), 335â349.
</div>
<div id="ref-hadlock2017QuantileparameterizedMethodsQuantifying" class="csl-entry" role="listitem">
Hadlock, C.C. (2017), <a href="https://doi.org/10.15781/T2F18SX41">Quantile-parameterized methods for quantifying uncertainty in decision analysis</a>, PhD thesis, University of Texas, Austin, TX.
</div>
<div id="ref-hadlock2017JohnsonQuantileParameterizedDistributions" class="csl-entry" role="listitem">
Hadlock, C.C., and J.E. Bickel (2017), <span>â<a href="https://doi.org/10.1287/deca.2016.0343">Johnson <span>Quantile-Parameterized Distributions</span></a>,â</span> <em>Decision Analysis</em>, 14(1), 35â64.
</div>
<div id="ref-hadlock2019GeneralizedJohnsonQuantileParameterized" class="csl-entry" role="listitem">
ââ (2019), <span>â<a href="https://doi.org/10.1287/deca.2018.0376">The <span>Generalized Johnson Quantile-Parameterized Distribution System</span></a>,â</span> <em>Decision Analysis</em>, 16(1), 67â85.
</div>
<div id="ref-hanea2021ExpertJudgementRisk" class="csl-entry" role="listitem">
Hanea, A.M., G.F. Nane, T. Bedford, and S. French (eds.) (2021), <em><a href="https://doi.org/10.1007/978-3-030-46474-5">Expert <span>Judgement</span> in <span>Risk</span> and <span>Decision Analysis</span></a></em>, vol. 293, Springer International Publishing, Cham.
</div>
<div id="ref-hartmann2020FlexiblePriorElicitation" class="csl-entry" role="listitem">
Hartmann, M., G. Agiashvili, P. BÃ¼rkner, and A. Klami (2020), <span>â<a href="https://arxiv.org/abs/2002.09868">Flexible <span>Prior Elicitation</span> via the <span>Prior Predictive Distribution</span></a>,â</span> <em>arXiv:2002.09868 [stat]</em>.
</div>
<div id="ref-haynes1997RobustnessRankingSelection" class="csl-entry" role="listitem">
Haynes, M.A., H.L. MacGillivray, and K.L. Mengersen (1997), <span>â<a href="https://doi.org/br3jtf">Robustness of ranking and selection rules using generalised g-and-k distributions</a>,â</span> <em>Journal of Statistical Planning and Inference</em>, 65(1), 45â66.
</div>
<div id="ref-haynes2005BayesianEstimationGandk" class="csl-entry" role="listitem">
Haynes, M., and K. Mengersen (2005), <span>â<a href="https://doi.org/dpgjv5">Bayesian estimation of g-and-k distributions using <span>MCMC</span></a>,â</span> <em>Computational Statistics</em>, 20(1), 7â30.
</div>
<div id="ref-hemming2018PracticalGuideStructured" class="csl-entry" role="listitem">
Hemming, V., M.A. Burgman, A.M. Hanea, M.F. McBride, and B.C. Wintle (2018), <span>â<a href="https://doi.org/10.1111/2041-210X.12857">A practical guide to structured expert elicitation using the <span>IDEA</span> protocol</a>,â</span> <em>Methods in Ecology and Evolution</em>, 9(1), 169â180.
</div>
<div id="ref-hoff2007ExtendingRankLikelihood" class="csl-entry" role="listitem">
Hoff, P.D. (2007), <span>â<a href="https://doi.org/10.1214/07-AOAS107">Extending the rank likelihood for semiparametric copula estimation</a>,â</span> <em>The Annals of Applied Statistics</em>, 1(1), 265â283.
</div>
<div id="ref-holzhauer2022ElicitingJudgementsDependent" class="csl-entry" role="listitem">
Holzhauer, B., L.V. Hampson, J.P. Gosling, B. Bornkamp, J. Kahn, M.R. Lange, W.-L. Luo, C. Brindicci, D. Lawrence, S. Ballerstedt, and A. OâHagan (2022), <span>â<a href="https://doi.org/10.1002/pst.2212">Eliciting judgements about dependent quantities of interest: <span>The SHeffield ELicitation Framework</span> extension and copula methods illustrated using an asthma case study</a>,â</span> <em>Pharmaceutical Statistics</em>, 21(5), 1005â1021.
</div>
<div id="ref-hubbard2019MultiDimensionalCounterBasedPseudo" class="csl-entry" role="listitem">
Hubbard, D.W. (2019), <span>â<a href="https://doi.org/10.1109/WSC40007.2019.9004773">A <span>Multi-Dimensional</span>, <span>Counter-Based Pseudo Random Number Generator</span> as a <span>Standard</span> for <span>Monte Carlo Simulations</span></a>,â</span> in: <em>2019 <span>Winter Simulation Conference</span> (<span>WSC</span>)</em>, pp. 3064â3073.
</div>
<div id="ref-jacob2017LikelihoodCalculationGandk" class="csl-entry" role="listitem">
Jacob, P. (2017), <em>Likelihood calculation for the g-and-k distribution</em>.
</div>
<div id="ref-jeffreys1939TheoryProbability" class="csl-entry" role="listitem">
Jeffreys, H. (1939), <em>The theory of probability</em>, OUP Oxford.
</div>
<div id="ref-jeong-soo2005WakebyDistributionMaximum" class="csl-entry" role="listitem">
Jeong-Soo, P. (2005), <span>â<a href="https://doi.org/10.5351/CKSS.2005.12.2.443"><span>Wakeby Distribution and the Maximum Likelihood Estimation Algorithm in Which Probability Density Function Is Not Explicitly Expressed</span></a>,â</span> <em>Communications for Statistical Applications and Methods</em>, 12(2), 443â451.
</div>
<div id="ref-johnson1997TriangularDistributionProxy" class="csl-entry" role="listitem">
Johnson, D. (1997), <span>â<a href="https://doi.org/10.1111/1467-9884.00091">The triangular distribution as a proxy for the beta distribution in risk analysis</a>,â</span> <em>Journal of the Royal Statistical Society: Series D (The Statistician)</em>, 46(3), 387â398.
</div>
<div id="ref-johnson1994ContinuousUnivariateDistributions" class="csl-entry" role="listitem">
Johnson, N.L., S. Kotz, and N. Balakrishnan (1994), <em>Continuous univariate distributions</em>, 2nd ed, Wiley, New York.
</div>
<div id="ref-jones2011SkewnessInvariantMeasuresKurtosis" class="csl-entry" role="listitem">
Jones, M.C., J.F. Rosco, and A. Pewsey (2011), <span>â<a href="https://doi.org/10.1198/tast.2011.10194">Skewness-<span>Invariant Measures</span> of <span>Kurtosis</span></a>,â</span> <em>The American Statistician</em>, 65(2), 89â95.
</div>
<div id="ref-kadane1980PredictiveStructuralMethods" class="csl-entry" role="listitem">
Kadane, J.B. (1980), <span>âPredictive and structural methods for eliciting prior distributions,â</span> in: A. Zellner (ed.), <em>Bayesian <span>Analysis</span> in <span>Econometrics</span> and <span>Statistics</span>: <span>Essays</span> in Honor of <span>Harold Jeffreys</span></em>, North Holland Publishing Company, Amsterdam, pp. 89â93.
</div>
<div id="ref-kadane1998ExperiencesElicitation" class="csl-entry" role="listitem">
Kadane, J., and L.J. Wolfson (1998), <span>â<a href="https://doi.org/cvdn73">Experiences in elicitation</a>,â</span> <em>Journal of the Royal Statistical Society: Series D (The Statistician)</em>, 47(1), 3â19.
</div>
<div id="ref-karian2003ComparisonGLDFitting" class="csl-entry" role="listitem">
Karian, Z.A., and E.J. Dudewicz (2003), <span>âComparison of <span>GLD Fitting Methods</span>: <span>Superiority</span> of <span>Percentile Fits</span> to <span>Moments</span> in <span>L</span><span>^</span>2 <span>Norm</span>,â</span> <em>Journal of The Iranian Statistical Society</em>, 2(2), 171â187.
</div>
<div id="ref-karian2019FittingStatisticalDistributions" class="csl-entry" role="listitem">
ââ (2019), <em>Fitting <span>Statistical Distributions</span>: The generalized lambda distribution and generalized bootstrap methods.</em>, CRC Press, S.l.
</div>
<div id="ref-keelin2016MetalogDistributions" class="csl-entry" role="listitem">
Keelin, T.W. (2016), <span>â<a href="https://doi.org/10.1287/deca.2016.0338">The <span>Metalog Distributions</span></a>,â</span> <em>Decision Analysis</em>, 13(4), 243â277.
</div>
<div id="ref-keelin2017MetalogDistributionsFeasibility" class="csl-entry" role="listitem">
ââ (2017), <em>The <span>Metalog Distributions</span> - <span>Feasibility</span></em>.
</div>
<div id="ref-keelin2021MetalogDistributionsVirtually" class="csl-entry" role="listitem">
Keelin, T.W., and R.A. Howard (2021), <span>âThe <span>Metalog Distributions</span>: <span>Virtually Unlimited Shape Flexibility</span>, <span>Combining Expert Opinion</span> in <span>Closed Form</span>, and <span>Bayesian Updating</span> in <span>Closed Form</span>,â</span> Preprint, OSF Preprints.
</div>
<div id="ref-keelin2011QuantileParameterizedDistributions" class="csl-entry" role="listitem">
Keelin, T.W., and B.W. Powley (2011), <span>â<a href="https://doi.org/10.1287/deca.1110.0213">Quantile-<span>Parameterized Distributions</span></a>,â</span> <em>Decision Analysis</em>, 8(3), 206â219.
</div>
<div id="ref-kim2004MoreRobustEstimation" class="csl-entry" role="listitem">
Kim, T.-H., and H. White (2004), <span>â<a href="https://doi.org/10.1016/S1544-6123(03)00003-5">On more robust estimation of skewness and kurtosis</a>,â</span> <em>Finance Research Letters</em>, 1(1), 56â73.
</div>
<div id="ref-king2007FittingGeneralizedLambda" class="csl-entry" role="listitem">
King, R.A.R., and H.L. MacGillivray (2007), <span>â<a href="https://doi.org/10.1080/01966324.2007.10737708">Fitting the <span>Generalized Lambda Distribution</span> with <span>Location</span> and <span>Scale-Free Shape Functionals</span></a>,â</span> <em>American Journal of Mathematical and Management Sciences</em>, 27(3-4), 441â460.
</div>
<div id="ref-kotz2004BetaOtherContinuous" class="csl-entry" role="listitem">
Kotz, S., and J.R. Van Dorp (2004), <em>Beyond beta: Other continuous families of distributions with bounded support and applications</em>, World Scientific, Singapore ; Hackensack, NJ.
</div>
<div id="ref-kurowicka2006UncertaintyAnalysisHigh" class="csl-entry" role="listitem">
Kurowicka, D., and R. Cooke (2006), <em>Uncertainty analysis with high dimensional dependence modelling</em>, Wiley, Chichester, England ; Hoboken, NJ.
</div>
<div id="ref-kurowicka2011DependenceModelingVine" class="csl-entry" role="listitem">
Kurowicka, D., and H. Joe (eds.) (2011), <em>Dependence modeling: Vine copula handbook</em>, World Scientific, Singapore.
</div>
<div id="ref-lampasi2008AlternativeApproachMeasurement" class="csl-entry" role="listitem">
Lampasi, D.A. (2008), <span>â<a href="https://doi.org/10.1016/j.measurement.2008.01.009">An alternative approach to measurement based on quantile functions</a>,â</span> <em>Measurement</em>, 41(9), 994â1013.
</div>
<div id="ref-lavine1995ApproximateLikelihoodQuantiles" class="csl-entry" role="listitem">
Lavine, M. (1995), <span>â<a href="https://doi.org/10.2307/2337641">On an <span>Approximate Likelihood</span> for <span>Quantiles</span></a>,â</span> <em>Biometrika</em>, 82(1), 220â222.
</div>
<div id="ref-macgillivray1992ShapePropertiesGandh" class="csl-entry" role="listitem">
Mac Gillivray, H.L. (1992), <span>â<a href="https://doi.org/bcmdwc">Shape properties of the g-and-h and johnson families</a>,â</span> <em>Communications in Statistics - Theory and Methods</em>, 21(5), 1233â1250.
</div>
<div id="ref-mikkola2021PriorKnowledgeElicitation" class="csl-entry" role="listitem">
Mikkola, P., O.A. Martin, S. Chandramouli, M. Hartmann, O.A. Pla, O. Thomas, H. Pesonen, J. Corander, A. Vehtari, S. Kaski, P.-C. BÃ¼rkner, and A. Klami (2021), <span>â<a href="https://arxiv.org/abs/2112.01380">Prior knowledge elicitation: <span>The</span> past, present, and future</a>,â</span> <em>arXiv:2112.01380 [stat]</em>.
</div>
<div id="ref-moors1988QuantileAlternativeKurtosis" class="csl-entry" role="listitem">
Moors, J.J.A. (1988), <span>â<a href="https://doi.org/10.2307/2348376">A <span>Quantile Alternative</span> for <span>Kurtosis</span></a>,â</span> <em>Journal of the Royal Statistical Society. Series D (The Statistician)</em>, 37(1), 25â32.
</div>
<div id="ref-morgan2014UseAbuseExpert" class="csl-entry" role="listitem">
Morgan, M.G. (2014), <span>â<a href="https://doi.org/10.1073/pnas.1319946111">Use (and abuse) of expert elicitation in support of decision making for public policy</a>,â</span> <em>Proceedings of the National Academy of Sciences</em>, 111(20), 7176â7184.
</div>
<div id="ref-mullen2023NnlsLawsonhansonAlgorithm" class="csl-entry" role="listitem">
Mullen, K.M., and I.H.M. van Stokkum (2023), <em>Nnls: <span>The</span> lawson-hanson algorithm for non-negative least squares (<span>NNLS</span>)</em>.
</div>
<div id="ref-myerson2005ProbabilityModelsEconomic" class="csl-entry" role="listitem">
Myerson, R.B. (2005), <em>Probability models for economic decisions</em>, Thomson/Brooke/Cole, Belmont, CA.
</div>
<div id="ref-nair2023PropertiesBivariateDistributions" class="csl-entry" role="listitem">
Nair, N.U., and B. Vineshkumar (2023), <span>â<a href="https://doi.org/10.1080/01966324.2021.2016522">Properties of <span>Bivariate Distributions Represented</span> through <span>Quantile Functions</span></a>,â</span> <em>American Journal of Mathematical and Management Sciences</em>, 0(0), 1â12.
</div>
<div id="ref-ohagan2019ExpertKnowledgeElicitation" class="csl-entry" role="listitem">
OâHagan, A. (2019), <span>â<a href="https://doi.org/10.1080/00031305.2018.1518265">Expert <span>Knowledge Elicitation</span>: <span>Subjective</span> but <span>Scientific</span></a>,â</span> <em>The American Statistician</em>, 73(sup1), 69â81.
</div>
<div id="ref-ohagan2006UncertainJudgementsEliciting" class="csl-entry" role="listitem">
OâHagan, A., C.E. Buck, A. Daneshkhah, J.R. Eiser, P.H. Garthwaite, D.J. Jenkinson, J.E. Oakley, and T. Rakow (2006), <em><a href="https://doi.org/10.1002/0470033312">Uncertain <span>Judgements</span>: <span>Eliciting Experts</span>â <span>Probabilities</span>: <span>O</span>â<span>Hagan</span>/<span>Uncertain Judgements</span>: <span>Eliciting Experts</span>â <span>Probabilities</span></a></em>, John Wiley &amp; Sons, Ltd, Chichester, UK.
</div>
<div id="ref-palisadecorporation2009GuideUsingRISK" class="csl-entry" role="listitem">
Palisade Corporation (2009), <span>âGuide to using@ <span>RISK</span>.: <span>Risk</span> analysis and simulation add-in for <span>Microsoft Excel</span>,â</span> USA Newfield<span>^</span> eNY NY.
</div>
<div id="ref-parzen1979NonparametricStatisticalData" class="csl-entry" role="listitem">
Parzen, E. (1979), <span>â<a href="https://doi.org/10.1080/01621459.1979.10481621">Nonparametric <span>Statistical Data Modeling</span></a>,â</span> <em>Journal of the American Statistical Association</em>, 74(365), 105â121.
</div>
<div id="ref-peng2023MixtureQuantilesEstimated" class="csl-entry" role="listitem">
Peng, C., Y. Li, and S. Uryasev (2023), <em><a href="https://doi.org/arXiv:2305.00081 [stat]">Mixture <span>Quantiles Estimated</span> by <span>Constrained Linear Regression</span></a></em>, arXiv.
</div>
<div id="ref-perepolkin2021HybridElicitationIndirect" class="csl-entry" role="listitem">
Perepolkin, D., B. Goodrich, and U. Sahlin (2021), <em><a href="https://doi.org/10.31219/osf.io/paby6">Hybrid elicitation and indirect <span>Bayesian</span> inference with quantile-parametrized likelihood</a></em>, OSF Preprints.
</div>
<div id="ref-perepolkin2023TenetsQuantilebasedInference" class="csl-entry" role="listitem">
ââ (2023), <span>â<a href="https://doi.org/10.1016/j.csda.2023.107795">The tenets of quantile-based inference in <span>Bayesian</span> models</a>,â</span> <em>Computational Statistics &amp; Data Analysis</em>, 187, 107795.
</div>
<div id="ref-powley2013QuantileFunctionMethods" class="csl-entry" role="listitem">
Powley, B.W. (2013), Quantile function methods for decision analysis, PhD thesis, Stanford University, Paolo Alto, CA.
</div>
<div id="ref-prangle2017GkPackageGandk" class="csl-entry" role="listitem">
Prangle, D. (2017), <span>â<a href="https://arxiv.org/abs/1706.06889">Gk: <span>An R Package</span> for the g-and-k and generalised g-and-h <span>Distributions</span></a>,â</span> <em>arXiv:1706.06889 [stat]</em>.
</div>
<div id="ref-pritsker2021ComparingBayesianPosterior" class="csl-entry" role="listitem">
Pritsker, J. (2021), <span>â<a href="https://doi.org/10.15626/MP.2020.2539">Comparing <span>Bayesian Posterior Passing</span> with <span class="nocase">Meta-analysis</span></a>,â</span> <em>Meta-Psychology</em>, 5.
</div>
<div id="ref-rahman2015ApplicabilityWakebyDistribution" class="csl-entry" role="listitem">
Rahman, A., M.A. Zaman, K. Haddad, S. El Adlouni, and C. Zhang (2015), <span>â<a href="https://doi.org/f6wzmh">Applicability of <span>Wakeby</span> distribution in flood frequency analysis: A case study for eastern <span>Australia</span></a>,â</span> <em>Hydrological Processes</em>, 29(4), 602â614.
</div>
<div id="ref-ramberg1974ApproximateMethodGenerating" class="csl-entry" role="listitem">
Ramberg, J.S., and B.W. Schmeiser (1974), <span>â<a href="https://doi.org/10.1145/360827.360840">An approximate method for generating asymmetric random variables</a>,â</span> <em>Communications of the ACM</em>, 17(2), 78â82.
</div>
<div id="ref-rayner2002NumericalMaximumLikelihood" class="csl-entry" role="listitem">
Rayner, G.D., and H.L. MacGillivray (2002), <span>â<a href="https://doi.org/10.1023/a:1013120305780">Numerical maximum likelihood estimation for the g-and-k and generalized g-and-h distributions</a>,â</span> <em>Statistics and Computing</em>, 12(1), 57â75.
</div>
<div id="ref-rubin1981EstimationParallelRandomized" class="csl-entry" role="listitem">
Rubin, D.B. (1981), <span>â<a href="https://doi.org/10.2307/1164617">Estimation in <span>Parallel Randomized Experiments</span></a>,â</span> <em>Journal of Educational Statistics</em>, 6(4), 377â401.
</div>
<div id="ref-sajeevkumar2014EstimationParameterMorgenstern" class="csl-entry" role="listitem">
Sajeevkumar, N.K., and M.R. Irshad (2014), <span>â<a href="https://doi.org/10.1177/0008068320140305">Estimation of <span>A Parameter</span> of <span>Morgenstern Type Bivariate Logistic Distribution</span> with <span>Equal Coefficients</span> of <span>Variation By Concomitants</span> of <span>Order Statistics</span></a>,â</span> <em>Calcutta Statistical Association Bulletin</em>, 66(3-4), 213â228.
</div>
<div id="ref-sharma2018RegularizationVariableSelection" class="csl-entry" role="listitem">
Sharma, R., and S. Das (2018), <span>â<a href="https://arxiv.org/abs/1709.05514">Regularization and <span>Variable Selection</span> with <span>Copula Prior</span></a>,â</span> <em>arXiv:1709.05514 [stat]</em>.
</div>
<div id="ref-smith2013BayesianApproachesCopula" class="csl-entry" role="listitem">
Smith, M.S. (2013), <span>â<a href="https://doi.org/10.1093/acprof:oso/9780199695607.001.0001">Bayesian <span>Approaches</span> to <span>Copula Modelling</span></a>,â</span> <em>arXiv:1112.4204 [stat]</em>.
</div>
<div id="ref-spetzler1975ProbabilityEncodingDecision" class="csl-entry" role="listitem">
Spetzler, C.S., and C.-A.S. StaÃ«l Von Holstein (1975), <span>â<a href="https://doi.org/10.1287/mnsc.22.3.340">Probability <span>Encoding</span> in <span>Decision Analysis</span></a>,â</span> <em>Management Science</em>, 22(3), 340â358.
</div>
<div id="ref-staudte2017ShapesThingsCome" class="csl-entry" role="listitem">
Staudte, R.G. (2017), <span>â<a href="https://doi.org/10.1080/02331888.2016.1277225">The <span>Shapes</span> of <span>Things</span> to <span>Come</span>: <span>Probability Density Quantiles</span></a>,â</span> <em>Statistics</em>, 51(4), 782â800.
</div>
<div id="ref-tarsitano2005EstimationGeneralizedLambda" class="csl-entry" role="listitem">
Tarsitano, A. (2005b), <span>â<a href="https://doi.org/10.1081/STA-200066334">Estimation of the <span>Generalized Lambda Distribution Parameters</span> for <span>Grouped Data</span></a>,â</span> <em>Communications in Statistics - Theory and Methods</em>, 34(8), 1689â1709.
</div>
<div id="ref-tarsitano2005FittingWakebyModel" class="csl-entry" role="listitem">
ââ (2005a), <span>âFitting <span>Wakeby</span> model using maximum likelihood,â</span> in: <em>Statistica e <span>Ambiente</span></em>, vol. 1, pp. 253â256.
</div>
<div id="ref-tukey1965WhichPartSample" class="csl-entry" role="listitem">
Tukey, J.W. (1965), <span>â<a href="https://doi.org/10.1073/pnas.53.1.127">Which <span>Part</span> of the <span>Sample Contains</span> the <span>Information</span>?</a>â</span> <em>Proceedings of the National Academy of Sciences</em>, 53(1), 127â134.
</div>
<div id="ref-vineshkumar2019BivariateQuantileFunctions" class="csl-entry" role="listitem">
Vineshkumar, B., and N.U. Nair (2019), <span>â<a href="https://doi.org/10.6092/issn.1973-2201/8024">Bivariate <span>Quantile Functions</span> and their <span>Applications</span> to <span>Reliability Modelling</span></a>,â</span> <em>Statistica</em>, 79(1), 3â21.
</div>
<div id="ref-wang2000ModelSelectionSemiparametric" class="csl-entry" role="listitem">
Wang, W., and M.T. Wells (2000), <span>â<a href="https://doi.org/10.2307/2669523">Model <span>Selection</span> and <span>Semiparametric Inference</span> for <span>Bivariate Failure-Time Data</span></a>,â</span> <em>Journal of the American Statistical Association</em>, 95(449), 62â72.
</div>
<div id="ref-welsh2018MoreorlessElicitationMOLE" class="csl-entry" role="listitem">
Welsh, M.B., and S.H. Begg (2018), <span>â<a href="https://doi.org/10.1007/s40070-018-0084-5">More-or-less elicitation (<span>MOLE</span>): Reducing bias in range estimation and forecasting</a>,â</span> <em>EURO Journal on Decision Processes</em>, 6(1), 171â212.
</div>
<div id="ref-wilson2018SpecificationInformativePrior" class="csl-entry" role="listitem">
Wilson, K.J. (2018), <span>â<a href="https://doi.org/10.1214/17-BA1068">Specification of <span>Informative Prior Distributions</span> for <span>Multinomial Models Using Vine Copulas</span></a>,â</span> <em>Bayesian Analysis</em>, 13(3), 749â766.
</div>
<div id="ref-wilson2021RecentAdvancesElicitation" class="csl-entry" role="listitem">
Wilson, K.J., F.G. Elfadaly, P.H. Garthwaite, and J.E. Oakley (2021), <span>â<a href="https://doi.org/10.1007/978-3-030-46474-5_2">Recent <span>Advances</span> in the <span>Elicitation</span> of&nbsp;<span>Uncertainty Distributions</span> from <span>Experts</span> for <span>Multinomial Probabilities</span></a>,â</span> in: A.M. Hanea, G.F. Nane, T. Bedford, S. French (eds.), <em>Expert <span>Judgement</span> in <span>Risk</span> and <span>Decision Analysis</span></em>, Springer International Publishing, Cham, pp. 19â51.
</div>
<div id="ref-wilson2023ReconciliationExpertPriors" class="csl-entry" role="listitem">
Wilson, K.J., M. Farrow, S. French, and D. Hartley (2023), <em><a href="https://arxiv.org/abs/2311.14487">Reconciliation of expert priors for quantities and events and application within the probabilistic <span>Delphi</span> method</a></em>, arXiv.
</div>
<div id="ref-winkler1980PriorInformationPredictive" class="csl-entry" role="listitem">
Winkler, R.L. (1980), <span>âPrior information, predictive distributions, and <span>Bayesian</span> model-building,â</span> <em>Bayesian Analysis in Econometrics and Statistics. North-Holland Publishing Company</em>, 95â109.
</div>
</div>
</section>

<div id="quarto-appendix" class="default"><section id="appendix-a.-distribution-functions" class="level1 appendix unnumbered"><h2 class="anchored quarto-appendix-heading">Appendix A. Distribution functions</h2><div class="quarto-appendix-contents">

<section id="myerson-distribution-1" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="myerson-distribution-1">Myerson Distribution</h2>
<p>The derivative of the quantile function with respect to the depth <span class="math inline">\(u\)</span> is the Quantile Density Function, which for Myerson distribution has the following form</p>
<p><span class="math display">\[
q(u\vert q_1,q_2,q_3,\alpha)=\begin{cases}
\rho\frac{\beta^\kappa\ln(\beta)}{(\beta-1)}\frac{q_{norm}(u)}{\Phi^{-1}(1-\alpha)}, \quad &amp;\beta \neq 1\\
\rho\frac{q_{norm}(u)}{\Phi^{-1}(1-\alpha)}, \quad &amp;\beta = 1
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(q_{norm}=\frac{d\Phi^{-1}(u)}{du}\)</span> is the quantile density function for the standard normal distribution.</p>
<p>The Myerson distribution is invertible. The distribution function of random variable <span class="math inline">\(X\)</span> has the form</p>
<p><span class="math display">\[
\begin{aligned}\;
\psi&amp;=\Phi^{-1}(1-\alpha)\left(\frac{\ln\left(1+\frac{(x-q_2)(\beta-1)}{\rho}\right)}{\ln(\beta)}\right)&amp;\\
F(x\vert q_1, q_2, q_3, \alpha)&amp;=\begin{cases}
\Phi(\psi), \quad &amp;\beta\neq 1\\
F_{normal}(x\vert q_2,\rho/\Phi^{-1}(1-\alpha) ), \quad &amp;\beta=1
\end{cases}
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\Phi()\)</span> is the CDF of the standard normal distribution and <span class="math inline">\(\Phi^{-1}()\)</span> is its inverse. <span class="math inline">\(F_{normal}(x\vert q_2,\rho/\Phi^{-1}(1-\alpha))\)</span> is the CDF of the normal distribution with mean <span class="math inline">\(\mu=q_2\)</span> and standard deviation <span class="math inline">\(\sigma=\rho/\Phi^{-1}(1-\alpha)\)</span>.</p>
<p>The derivative of the distribution function with respect to the random variable <span class="math inline">\(X\)</span> is the probability density function, which for the Myerson distribution takes the following form</p>
<p><span class="math display">\[
f(x\vert q_1, q_2, q_3, \alpha)=\begin{cases}
\frac{\Phi^{-1}(1-\alpha)(\beta-1)}{(\rho+(x-q_2)(\beta-1))\ln(\beta)}\varphi(\psi), \quad &amp;\beta\neq1\\
f_{normal}(x\vert q_2,\rho/\Phi^{-1}(1-\alpha)),\quad &amp;\beta=1
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\varphi()\)</span> is the probability density function of the standard normal distribution, <span class="math inline">\(f_{normal}(x\vert q_2,\frac{\rho}{\Phi^{-1}(1-\alpha)})\)</span> is the PDF of the normal distribution with the mean <span class="math inline">\(\mu=q_2\)</span> and standard deviation <span class="math inline">\(\sigma=\rho/\Phi^{-1}(1-\alpha))\)</span>.</p>
</section>
<section id="generalized-myerson-distributions" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="generalized-myerson-distributions">Generalized Myerson Distributions</h2>
<p>The Quantile Density Function of Generalized Myerson Distribution for <span class="math inline">\(u\neq0, u\neq1\)</span> is</p>
<p><span class="math display">\[
q_M(u\vert q_1,q_2,q_3,\alpha)=\begin{cases}
\rho\frac{\beta^\kappa\ln(\beta)}{(\beta-1)}\frac{s(u)}{S(1-\alpha)}, \quad &amp;\beta \neq 1\\
\rho\frac{s(u)}{S(1-\alpha)}, \quad &amp;\beta = 1
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(S(u)\)</span> is the quantile function and <span class="math inline">\(s(u)=\frac{dS(u)}{du}\)</span> is the quantile density function for the kernel distribution. When <span class="math inline">\(u=0\)</span> or <span class="math inline">\(u=1\)</span> the <span class="math inline">\(q_M(u)=\infty\)</span>.</p>
<p>The Generalized Myerson distribution is invertible. The distribution function of random variable <span class="math inline">\(X\)</span> has the form</p>
<p><span class="math display">\[
\begin{aligned}\;
\psi &amp;=S(1-\alpha)\left(\frac{\ln\left(1+\frac{(x-q_2)(\beta-1)}{\rho}\right)}{\ln(\beta)}\right)\\
F_M(x\vert q_1, q_2, q_3, \alpha)&amp;=\begin{cases}
F(\psi), \quad &amp;\beta\neq 1\\
q_2+ \frac{\rho}{S(1-\alpha)}F(x), \quad &amp;\beta=1
\end{cases}
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(F()\)</span> is the standard CDF of the kenel distribution and <span class="math inline">\(S()\)</span> is its inverse.</p>
<p>The derivative of the distribution function with respect to the random variable <span class="math inline">\(X\)</span> is the probability density function, which for the Myerson distribution takes the following form</p>
<p><span class="math display">\[
f_M(x\vert q_1, q_2, q_3, \alpha)=\begin{cases}
\frac{S(1-\alpha)(\beta-1)}{(\rho+(x-q_2)(\beta-1))\ln(\beta)}f(\psi), \quad &amp;\beta\neq1\\
f\left(\frac{x-q_2}{\rho/S(1-\alpha)}\right),\quad &amp;\beta=1
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(f()\)</span> is the probability density function of the standard kernel distribution. Compare it to the simplicity of the Quantile Density Function above.</p>
</section>
<section id="johnson-quantile-parameterized-distribution-1" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="johnson-quantile-parameterized-distribution-1">Johnson Quantile-Parameterized Distribution</h2>
<p>The JQPD-B quantile density function can be computed as</p>
<p><span class="math display">\[
q_B(p)=\begin{cases}
(u_b-l_b)\varphi(\xi+\lambda\sinh(\delta(z(p)+nc))) \times\\
\quad \lambda\cosh(\sigma(z(p)+nc)) \sigma q_{norm}(p), \quad &amp;n\neq 0\\
(u_b-l_b)\varphi\left(B+\left(\frac{H-L}{2c}\right)z(p)\right)
\times \left(\frac{H-L}{2c}\right)q_{norm}(p), \quad &amp;n=0
\end{cases}
\]</span></p>
<p>The JQPD-B distribution function</p>
<p><span class="math display">\[
F_B(x)=\begin{cases}
\Phi\left((2c/(H-L))(-B+z\left(\frac{x-l}{u-l}\right))\right), \quad &amp;n=0 \\
\Phi\left(\frac{1}{\delta}\sinh^{-1}\left(\frac{1}{\lambda}\left(z\left(\frac{x-l}{u-l}\right)-\xi\right)\right)-nc\right), \quad &amp;n\neq0
\end{cases}
\]</span></p>
<p>The JQPD-B probability density function (PDF) is</p>
<p><span class="math display">\[
\begin{gathered}
f(x)=\begin{cases}
\frac{2c}{(H-L)(u_b-l_b)}\frac{1}{\varphi\left(z\left(\frac{x-l_b}{u_b-l_b}\right)\right)}\varphi\left(\frac{2c}{H-L}\left(-B+z\left(\frac{x-l_b}{u-l_b}\right)\right)\right), \quad &amp;n=0\\
\frac{1}{\delta}\frac{1}{u_b-l_b}\varphi\left(-nc+\frac{1}{\delta}\sinh^{-1}\left(\frac{1}{\lambda}\left(-\xi+z\left(\frac{x-l_b}{u_b-l_b}\right)\right)\right)\right) \times \\ \indent
\frac{1}{\varphi\left(z\left(\frac{x-l_b}{u_b-l_b}\right)\right)}\frac{1}{\sqrt{\lambda^2+\left(-\xi+z\left(\frac{x-l_b}{u_b-l_b}\right)\right)^2}}, \quad &amp;n\neq 0\\
\end{cases}
\end{gathered}
\]</span></p>
<p>J-QPD-S quantile density function</p>
<p><span class="math display">\[
q_S(p)=\begin{cases}
\theta\exp\left(\lambda\delta z(p)\right)\lambda\delta q_{norm}(p), \quad &amp;n=0\\
\theta\exp\left(\lambda\sinh^{-1}(\delta z(p))+\sinh^{-1}(nc\delta)\right)\lambda\frac{1}{\sqrt{1+(\delta z(p))^2}}\delta q_{norm}(p), \quad &amp;n\neq0\\
\end{cases}
\]</span></p>
<p>J-QPD-S distribution function</p>
<p><span class="math display">\[
F_S(x)=\begin{cases}
F_{lnorm}(x-l_b\vert \ln(\theta), \frac{H-B}{c}), \quad &amp;n=0\\
\Phi\left(\frac{1}{\delta}\sinh\left(\sinh^{-1}\left(\frac{1}{\lambda}\ln\frac{x-l_b}{\theta}\right)-\sinh^{-1}(nc\delta)\right)\right), \quad &amp;n\neq0\\
\end{cases}
\]</span></p>
<p>J-QPD-S probability density function (PDF)</p>
<p><span class="math display">\[
f_S(x)=\begin{cases}
\frac{1}{x\sigma\sqrt{2\pi}}\exp\left(-\frac{(\ln x-ln\xi)^2}{2\frac{(H-B)^2}{c^2}}\right), \quad &amp;n=0\\
\varphi\left(\frac{\sinh(\sinh^{-1}(cn\sigma)-\sinh^{-1}(\frac{1}{\lambda}\ln\frac{x-l_b}{\theta}))}{\delta}\right)\frac{\cosh(\sinh^{-1}(cn\delta)-\sinh^{-1}(\frac{1}{\lambda}\ln\frac{x-l_b}{\theta}))}{(x-l_b)\delta\lambda\sqrt{1+\left(\frac{\ln\frac{x-l_b}{\theta}}{\lambda}\right)^2}}, \quad &amp;n \neq 0
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\mu=\ln\xi\)</span> and <span class="math inline">\(\sigma=\frac{H-B}{c}\)</span>.</p>
</section>
<section id="metalog-distribution" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="metalog-distribution">Metalog distribution</h2>
<p>This section recapitulates ideas and formulas provided in <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span> with our own notation and minor reinterpretations.</p>
<p>Metalog distribution is created from the logistic quantile function <span class="math inline">\(Q(p)=\mu+s\text{logit}(p)\)</span>, where <span class="math inline">\(\mu\)</span> is the mean, <span class="math inline">\(s\)</span> is proportional to the standard deviation such that <span class="math inline">\(\sigma=s\pi/\sqrt3\)</span>, <span class="math inline">\(p\)</span> is the probability <span class="math inline">\(p \in [0,1]\)</span>. The metalog quantile function is built by substitution and series expansion of its parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(s\)</span> with the polynomial of the form:</p>
<p><span class="math display">\[
\begin{aligned}\;
&amp;\mu=a_1+a_4(p-0.5)+a_5(p-0.5)^2+a_7(p-0.5)^3+a_9(p-0.5)^4+\dots, \\
&amp; s=a_2+a_3(p-0.5)+a_6(p-0.5)^2+a_8(p-0.5)^3+a_{10}(p-0.5)^4+\dots,
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(a_i, \; i \in (1\dots n)\)</span> are real constants. Given a size-<span class="math inline">\(m\)</span> QPT <span class="math inline">\(\{p, q\}_m\)</span>, where <span class="math inline">\(p=\{p_1\dots p_m\}\)</span> and <span class="math inline">\(q=\{q_1\dots q_m\}\)</span> the vector of coefficients <span class="math inline">\(a=\{a_1\dots a_m\}\)</span> can be determined through the set of linear equations.</p>
<p><span class="math display">\[
\begin{aligned}\;
&amp;q_1=a_1+a_2\text{logit}(p_1)+a_3(p_1-0.5)\text{logit}(p_1)+a_4(p_1-0.5)+\cdots,\\
&amp;q_2=a_1+a_2\text{logit}(p_2)+a_3(p_2-0.5)\text{logit}(p_2)+a_4(p_2-0.5)+\cdots,\\
&amp;\vdots\\
&amp;q_m=a_1+a_2\text{logit}(p_m)+a_3(p_m-0.5)\text{logit}(p_m)+a_4(p_m-0.5)+\cdots.\\
\end{aligned}
\]</span></p>
<p>In the matrix form, this system of equations is equivalent to <span class="math inline">\(q=\mathbb{P}a\)</span>, where <span class="math inline">\(q\)</span> and <span class="math inline">\(a\)</span> are column vectors and <span class="math inline">\(\mathbb{P}\)</span> is a <span class="math inline">\(m \times n\)</span> matrix:</p>
<p><span class="math display">\[
\mathbb{P} = \left[\begin{array}{lllll}
1  &amp;\text{logit}(p_1) &amp;(p_1-0.5)\text{logit}(p_1) &amp;(p_1-0.5) &amp;\cdots\\
1  &amp;\text{logit}(p_2) &amp;(p_2-0.5)\text{logit}(p_2) &amp;(p_2-0.5) &amp;\cdots\\
   &amp;                  &amp;\vdots\\
1  &amp;\text{logit}(p_m) &amp;(p_m-0.5)\text{logit}(p_m) &amp;(p_m-0.5) &amp;\cdots
\end{array}\right]
\]</span></p>
<p>If <span class="math inline">\(m=n\)</span> and <span class="math inline">\(\mathbb{P}\)</span> is invertible, then the vector of coefficients <span class="math inline">\(a\)</span> of this <em>properly parameterized</em> metalog QPD can be uniquely determined by</p>
<p><span id="eq-nmetalogAsMatrixeq"><span class="math display">\[
a=\mathbb{P}^{-1}q
\tag{4}\]</span></span></p>
<p>If <span class="math inline">\(m &gt; n\)</span> and <span class="math inline">\(\mathbb{P}\)</span> has a rank of at least <span class="math inline">\(n\)</span>, then the vector of coefficients <span class="math inline">\(a\)</span> of the <em>approximated</em> metalog QPD, can be estimated using</p>
<p><span class="math display">\[
a=[\mathbb{P}^T\mathbb{P}]^{-1}\mathbb{P}^Tq
\]</span></p>
<p>The matrix to be inverted is always <span class="math inline">\(n \times n\)</span> regardless of the size <span class="math inline">\(m\)</span> of QPT used.</p>
<p>Metalog <em>quantile function</em> (QF) with <span class="math inline">\(n\)</span> terms <span class="math inline">\(Q_{M_n}(u\vert a)\)</span> can be expressed as</p>
<p><span id="eq-metalogQFeq"><span class="math display">\[
Q_{M_n}(u\vert a)=\begin{cases}
a_1+a_2\text{logit}(u), \text{ for } n=2, \\
a_1+a_2\text{logit}(u)+a_3(u-0.5)\text{logit}(u), \text{ for } n=3, \\
a_1+a_2\text{logit}(u)+a_3(u-0.5)\text{logit}(u)+a_4(u-0.5), \text{ for } n=4, \\
Q_{M_{n-1}} + a_n(u-0.5)^{(n-1)/2}, \text{ for odd } n \geq 5, \\
Q_{M_{n-1}} + a_n(u-0.5)^{n/2-1}\text{logit}(u), \text{ for even } n \geq 6, \\
\end{cases}
\tag{5}\]</span></span></p>
<p>where <span class="math inline">\(u \in [0,1]\)</span> is the cumulative probability and <span class="math inline">\(a\)</span> is the size-<span class="math inline">\(n\)</span> parameter vector of real constants <span class="math inline">\(a=\{a_1\dots a_n\}\)</span>.</p>
<p>The metalog <em>quantile density function</em> (QDF) can be found by differentiating the <a href="#eq-metalogQFeq" class="quarto-xref">Equation&nbsp;5</a> with respect to <span class="math inline">\(u\)</span>:</p>
<p><span id="eq-metalogQDFeq"><span class="math display">\[
\begin{gathered}
q_{M_n}(u\vert a)=\begin{cases}
a_2\mathcal I(u), \text{ for } n=2, \\
a_2\mathcal I(u)+a_3\left((u-0.5)\mathcal I(u)+\text{logit}(u) \right), \text{ for } n=3, \\
a_2\mathcal I(u) + a_3\left((u-0.5)\mathcal I(u)+\text{logit}(u) \right)+ a_4,  \text{ for } n=4, \\
q_{M_{n-1}} + 0.5a_n(n-1)(u-0.5)^{(n-3)/2}, \text{ for odd } n \geq 5, \\
q_{M_{n-1}} + a_n((u-0.5)^{n/2-1}\mathcal I(u)+\\ \indent (0.5n-1)(u-0.5)^{n/2-2}\text{logit}(u)), \text{ for even } n \geq 6, \\
\end{cases}
\end{gathered}
\tag{6}\]</span></span></p>
<p>where <span class="math inline">\(\mathcal I(u)=[u(1-u)]^{-1}\)</span>. The constants <span class="math inline">\(a\)</span> are feasible iif <span class="math inline">\(q_{M_{n}}(u\vert a)&gt;0, \;\forall u \in [0,1]\)</span>.</p>
<p>Metalog <em>density quantile function</em> (DQF), referred to as the âmetalog pdfâ in <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span> can be obtained by <span class="math inline">\(f(Q_{M_n}(u\vert a))=[q_{M_n}(u\vert a)]^{-1}\)</span>.</p>
<p>Metalog <em>cumulative distribution function</em> (CDF) <span class="math inline">\(F_{M_n}(x\vert a)\)</span> does not have an explicit form because <span class="math inline">\(Q_{M_n}(u\vert a)\)</span> is not invertible <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span>. It is, however, possible to approximate <span class="math inline">\(\widehat Q^{-1}_{M_n}(x\vert a)\)</span> using approximation.</p>
<p>Metalog distribution is defined for all <span class="math inline">\(x \in \mathbb R\)</span> on the real line. <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span> provides semi-bounded <em>log-metalog</em>, and the bounded <em>logit-metalog</em> variations of the metalog distribution. As the names suggest, this is achieved through the variable substitution with <span class="math inline">\(z=\ln(x-b_l)\)</span> or <span class="math inline">\(z=-\ln(b_u-x)\)</span> for the semi-bounded case, and <span class="math inline">\(z=\ln((x-b_l)/(b_u-x))\)</span> for the bounded case, where <span class="math inline">\(z\)</span> is metalog-distributed and <span class="math inline">\(b_l, b_u\)</span> are the lower and upper limits, respectively. Substituting one of the transformations into the QF and QDF functions above, yields semi-bounded or bounded metalog distribution. For the exact formulae of the log-metalog and logit-metalog refer to <span class="citation" data-cites="keelin2016MetalogDistributions">(<a href="#ref-keelin2016MetalogDistributions" role="doc-biblioref">Keelin, 2016</a>)</span>.</p>
</section>
<section id="csw-gld" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="csw-gld">CSW GLD</h2>
<p>Quantile density function for the CSW GLD is provided in <span class="citation" data-cites="chalabi2012FlexibleDistributionModeling">(<a href="#ref-chalabi2012FlexibleDistributionModeling" role="doc-biblioref">Chalabi et al., 2012</a>)</span></p>
<p><span class="math display">\[
\begin{gathered}
q(u\vert\tilde\sigma,\chi,\xi)= \frac{\tilde\sigma}{S(0.75\vert\chi,\xi)-S(0.25\vert\chi,\xi)}
s(u\vert\chi,\xi) \\
s(u\vert\chi,\xi)=\frac{d}{du}S(u\vert\chi,\xi)=u^{\alpha+\beta-1}+(1-u)^{\alpha-\beta-1}
\end{gathered}
\]</span></p>
<div style="page-break-after: always;"></div>
</section>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>